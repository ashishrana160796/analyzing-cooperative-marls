{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stablebaselines_SizeThreeGridRoadEnv_rendering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing the latest stable-baselines3 library.\n",
        "# !pip install stable-baselines3\n",
        "!pip install stable-baselines3\n",
        "# Ignoring the restart runtime instruction and continue with the cell execution."
      ],
      "metadata": {
        "id": "34ag2hg60oia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "W5RN83LAqWyB"
      },
      "outputs": [],
      "source": [
        "# OpenAI gym related import statements.\n",
        "# Building a simpler environment that works with stablebaselines.\n",
        "import os\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np  \n",
        "import random\n",
        "from gym.envs.registration import EnvSpec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: The 3x3 road network environment doesn't rotate in its simple\n",
        "# setting implementation.\n",
        "# Implementation of the Simple 3x3 road network for MultiAgent RL.\n",
        "class SizeThreeSimpleGridRoadEnv(gym.Env):\n",
        "    # Defining the Driving Agent with name and gas values plus package flag.\n",
        "    class DriverAgent():\n",
        "        def __init__(self, name, gas, package):\n",
        "            self.name = name\n",
        "            self.gas = gas\n",
        "            self.package = package\n",
        "\n",
        "    def __init__(self):\n",
        "        # super(SizeThreeSimpleGridRoadEnv, self).__init__()\n",
        "        # Defining different possible world configurations.\n",
        "        self.world_one = np.array([[1, 0, 0],\n",
        "                      [3, 0, 2],\n",
        "                      [0, 0, 4]])\n",
        "        # self.world_two = np.rot90(self.world_one)\n",
        "        # self.world_three = np.rot90(self.world_two)\n",
        "        # self.world_four = np.rot90(self.world_three)\n",
        "        # Even the initial world configuration is defined to be different upon\n",
        "        # environment instantiation. \n",
        "        # prob = random.uniform(0, 1)\n",
        "        # Default value assignment below.\n",
        "        self.world = self.world_one\n",
        "        # if prob > 0.25 and prob <= 0.25:\n",
        "        #     self.world = self.world_two\n",
        "        # elif prob > 0.5 and prob <= 0.75:\n",
        "        #     self.world = self.world_three\n",
        "        # elif prob > 0.75 and prob <= 1:\n",
        "        #     self.world = self.world_four\n",
        "        self.world_start = self.world # This 'world_start', if reset() is called, never gets used.\n",
        "        # Adding five actions for the environment.\n",
        "        # 0: up, 1: right, 2: down, 3: left, 4: stay/pass chance, 5: drop\n",
        "        # When agent reaches at package location it automatically picks up the package.\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "        shape_0 = np.size(self.world_start, 0)\n",
        "        shape_1 = np.size(self.world_start, 1)\n",
        "        self.observation_space = spaces.Box(low=0,\n",
        "                                            high=4,\n",
        "                                            shape=(shape_0 + 1, shape_1),\n",
        "                                            dtype=np.int16)\n",
        "        self.reward_range = (-10, 10)\n",
        "        self.current_episode = 0\n",
        "        self.success_episode = []\n",
        "        # Defining the driver agents in the environment.\n",
        "        self.agent_one = self.DriverAgent(1,3,0) # 3 integer value, when carrying package.\n",
        "        self.agent_two = self.DriverAgent(2,3,0) # 3 integer value, when carrying package.\n",
        "        self.spec = EnvSpec(\"SizeThreeSimpleGridRoadEnv-v0\")\n",
        "\n",
        "    def reset(self):\n",
        "        # Game like formulation, each player agent moves one step at a time.\n",
        "        self.agent_one = self.DriverAgent(1,3,0) # Instantiating agent 1 again.\n",
        "        self.agent_two = self.DriverAgent(2,3,0) # Instantiating agent 2 again.\n",
        "        self.current_player = self.agent_one\n",
        "        # 'P' means the game is playable, 'W' means delivered, 'L' means no delivery.\n",
        "        self.state = 'P'\n",
        "        self.current_step = 0\n",
        "        self.max_step = 30 # agent can choose not move as an alternate choice.\n",
        "        # Selecting a world at random to function with.\n",
        "        # Even the initial world configuration should be different.\n",
        "        # prob = random.uniform(0, 1)\n",
        "        # if prob > 0.25 and prob <= 0.25:\n",
        "        #     self.world_start = self.world_two\n",
        "        # elif prob > 0.5 and prob <= 0.75:\n",
        "        #     self.world_start = self.world_three\n",
        "        # elif prob > 0.75 and prob <= 1:\n",
        "        #     self.world_start = self.world_four\n",
        "        # elif prob < 0.25:\n",
        "        #     self.world_start = self.world_one\n",
        "        self.world_start = self.world_one    \n",
        "        self.world = np.copy(self.world_start) # The self.world can be different from intial world.\n",
        "        # no exploration_prize and bonus_reward as per my design.\n",
        "        return self._next_observation()\n",
        "    \n",
        "    def _next_observation(self):\n",
        "        obs = self.world\n",
        "        data_to_add = [0] * np.size(self.world, 1)\n",
        "        data_to_add[0] = self.current_player.name # adding current player's label in the observation.\n",
        "        obs = np.append(obs, [data_to_add], axis=0)\n",
        "        # Observation Sample provided below for reference:\n",
        "        # last row, represents 'data_to_add' vector.\n",
        "        # array([[1, 0, 0],\n",
        "        #         [3, 0, 2],\n",
        "        #         [0, 0, 4],\n",
        "        #         [1, 0, 0]])\n",
        "        return obs\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        # Agent's name is matched to the array entries for index identification.\n",
        "        # 'current_player.name' should be updated alongside the array values.\n",
        "        current_pos = np.where(self.world == self.current_player.name)\n",
        "        # the current agent must have gas in it.\n",
        "        if self.current_player.gas > 0:\n",
        "            if action == 0:\n",
        "                next_pos = (current_pos[0] - 1, current_pos[1]) # Agent moving upwards.\n",
        "\n",
        "                if next_pos[0] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 1:\n",
        "                next_pos = (current_pos[0], current_pos[1] + 1)\n",
        "                limit = np.size(self.world, 1)\n",
        "\n",
        "                if next_pos[1] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 2:\n",
        "                next_pos = (current_pos[0] + 1, current_pos[1])\n",
        "                limit = np.size(self.world, 0)\n",
        "\n",
        "                if next_pos[0] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            elif action == 3:\n",
        "                next_pos = (current_pos[0], current_pos[1] - 1)\n",
        "\n",
        "                if next_pos[1] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] >= 0 and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            # Newly added logic based on three new possible actions.\n",
        "            elif action == 4 and self.current_player.name != 1: # passing is only allowed for agent 2.\n",
        "                pass # Corresponding agent selects to not move at their chance.\n",
        "            '''\n",
        "            elif action == 5: # If agent is over the package, it has to pick it up, environment cases encoded above.\n",
        "                # Agent can choose to drop the package, if it is loaded with it.\n",
        "                # After, dropping the package the agent should dissappear.\n",
        "                if self.current_player.package == 3:\n",
        "                    if self.world[current_pos] == 0:\n",
        "                        self.world[current_pos] = 3\n",
        "                        # agent dissappears from the grid after this drop.\n",
        "                    elif self.world[current_pos] == 4: # Added as extra case, functionally possibly won't be triggered.\n",
        "                        self.world[current_pos] = self.current_player.name\n",
        "                        self.state = 'W'\n",
        "            '''\n",
        "        else:\n",
        "            # Player 1's gas is supposed to go empty first.\n",
        "            # Therefore, upon having empty gas tank player should be allowed to\n",
        "            # drop the package in the environment and disappear from the location.\n",
        "            if self.current_player.package == 3:\n",
        "                self.world[current_pos] = self.current_player.package\n",
        "                # agent dissappears from the grid after this drop.\n",
        "            else:\n",
        "                self.world[current_pos] = 0 # If gas is finished, agent should dissappear.\n",
        "\n",
        "        # If gas is empty for both agents, the episode should stop at that instant.\n",
        "        if self.agent_one.gas == 0 and self.agent_two.gas == 0:\n",
        "            self.state = 'L'\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self._take_action(action)\n",
        "        self.current_step += 1\n",
        "        # Uncomment the below statement out, while debugging.\n",
        "        # print(self.world) \n",
        "\n",
        "        if self.state == \"W\":\n",
        "            reward = 1\n",
        "            done = True\n",
        "        elif self.state == 'L':\n",
        "            reward = -10\n",
        "            done = True\n",
        "        elif self.state == 'P':\n",
        "            reward = 0 # sparse reward encoding, only rewarded when episode ends.\n",
        "            done = False\n",
        "\n",
        "        if self.current_step >= self.max_step:\n",
        "            print(f'New episode number {self.current_episode + 1}')\n",
        "            done = True\n",
        "\n",
        "        # agents object used to identify agent properties.\n",
        "        if self.current_player.name == 1 and self.current_step > 2:\n",
        "            self.current_player = self.agent_two\n",
        "        elif self.current_player.name == 2:\n",
        "            self.current_player = self.agent_one\n",
        "\n",
        "        if done:\n",
        "            self.render_episode(self.state)\n",
        "            self.current_episode += 1\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, done, {'state': self.state}\n",
        "\n",
        "    def render_episode(self, win_or_lose):\n",
        "        # Storing the rendered episodes in a file.\n",
        "        self.success_episode.append(\n",
        "            'Success' if win_or_lose == 'W' else 'Failure')\n",
        "        file = open('render.txt', 'a')\n",
        "        file.write('----------------------------\\n')\n",
        "        file.write(f'Episode number {self.current_episode}\\n')\n",
        "        file.write(\n",
        "            f'{self.success_episode[-1]} in {self.current_step} steps\\n')\n",
        "        file.close()"
      ],
      "metadata": {
        "id": "2pPscl6L7Wr8"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stable_baseline3 library related import statements.\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv # it's usage produces 'spec' related error.\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv # it's usage produces 'spec' related error.\n",
        "from stable_baselines3 import A2C"
      ],
      "metadata": {
        "id": "bpbJzTgt5LcI"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the environment for testing.\n",
        "env_simple = SizeThreeSimpleGridRoadEnv()\n",
        "# Logs will be saved in log_dir/monitor.csv\n",
        "# env_simple = Monitor(env_simple, log_dir)"
      ],
      "metadata": {
        "id": "LJjDiyrTkN8O"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple = A2C(\"MlpPolicy\", env_simple, verbose=0)\n",
        "model_simple.learn(total_timesteps=100000, log_interval=4)"
      ],
      "metadata": {
        "id": "dx5z0giWkOC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DQN Model Learning for Simple Road Environment Task\n",
        "# del env_simple\n",
        "# del model_simple"
      ],
      "metadata": {
        "id": "oHAGMzfMytx1"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the RL model instances.\n",
        "print(model_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nMQFv0e2mwK",
        "outputId": "e0cde4de-9e20-4279-a8ca-a2960a157424"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<stable_baselines3.a2c.a2c.A2C object at 0x7f6e8d71ea90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import colors\n",
        "\n",
        "def agent_rendering(obs_list):\n",
        "    fps = 2\n",
        "    nSeconds = 15\n",
        "    # matching the dimension dimension of the obs_list with 'nSeconds*fps' values.\n",
        "    snapshots = obs_list # [ np.random.rand(3,3) for _ in range(nSeconds*fps) ]\n",
        "\n",
        "    # First set up the figure, the axis, and the plot element we want to animate\n",
        "    fig = plt.figure( figsize=(3,4) )\n",
        "    colormap = colors.ListedColormap([\"lightsteelblue\", \"chocolate\", \"tomato\", \"navajowhite\", \"yellowgreen\", \"lightpink\"])\n",
        "    bounds = [0,1,2,3,4,5]\n",
        "    norm = colors.BoundaryNorm(bounds, colormap.N)\n",
        "    a = snapshots[0]\n",
        "    im = plt.imshow(a, cmap=colormap, norm=norm)\n",
        "    def animate_func(i):\n",
        "        if i % fps == 0:\n",
        "            print( '.', end ='' )\n",
        "        im.set_array(snapshots[i])\n",
        "        return [im]\n",
        "    anim = animation.FuncAnimation(\n",
        "                               fig, \n",
        "                               animate_func, \n",
        "                               frames = nSeconds * fps,\n",
        "                               interval = 1000 / fps, # in ms\n",
        "                               )\n",
        "    anim.save('test_anim.mp4', fps=fps, extra_args=['-vcodec', 'libx264'])\n",
        "    print('Done!')"
      ],
      "metadata": {
        "id": "zsOIKNWa6O6y"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing obs data into simple road env for ppo algorithm.\n",
        "ppo_simple_obs_list = []\n",
        "env_simple = SizeThreeSimpleGridRoadEnv()\n",
        "result_test = []\n",
        "obs = env_simple.reset()\n",
        "for i in range(200):\n",
        "    action, _states = model_simple.predict(obs)\n",
        "    # print(action)\n",
        "    obs, reward, done, info = env_simple.step(action)\n",
        "    \n",
        "    ppo_simple_obs_list.append(obs)\n",
        "    if done:\n",
        "        result_test.append(info['state'])\n",
        "\n",
        "# Printing the output results w/ successful completions.\n",
        "result_stat = result_test.count('W') / len(result_test)\n",
        "print(f'Success rate: {result_stat * 100} %')"
      ],
      "metadata": {
        "id": "GcOzl_0Tw_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing obs data into simple road env for random walk testing for the environment.\n",
        "import random\n",
        "ppo_simple_obs_list = []\n",
        "env_simple = SizeThreeSimpleGridRoadEnv()\n",
        "result_test = []\n",
        "obs = env_simple.reset()\n",
        "for i in range(200):\n",
        "    action = random.randint(0, 4) # model_simple.predict(obs)\n",
        "    obs, reward, done, info = env_simple.step(action)\n",
        "    # print(info)\n",
        "    ppo_simple_obs_list.append(obs)\n",
        "    if done:\n",
        "        result_test.append(info['state'])\n",
        "\n",
        "# Printing the output results w/ successful completions.\n",
        "result_stat = result_test.count('W') / len(result_test)\n",
        "print(f'Success rate: {result_stat * 100} %')"
      ],
      "metadata": {
        "id": "okwe12Ni_y3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_rendering(ppo_simple_obs_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "igdSxCaE5M7o",
        "outputId": "1cb80818-df96-4979-98b0-b7af03f714de"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".....................Done!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "save_path = \"/content/videos/result.mp4\"\n",
        "# Compressed video path\n",
        "compressed_path = \"test_anim.mp4\"\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=175 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "2A3yGVZ_3B8v",
        "outputId": "18010074-74c4-424a-e38f-08f8d3b3ff3b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=175 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the '.mp4' video into a '.gif' file.\n",
        "from moviepy.editor import *\n",
        "clip = (VideoFileClip(\"test_anim.mp4\"))\n",
        "clip.write_gif(\"video.gif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_6_1cMwYJLE",
        "outputId": "9bfa27de-b487-4ba7-928a-52749b6f6eec"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3235840/45929032 bytes (7.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7176192/45929032 bytes (15.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11091968/45929032 bytes (24.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15106048/45929032 bytes (32.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19021824/45929032 bytes (41.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22798336/45929032 bytes (49.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26697728/45929032 bytes (58.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30572544/45929032 bytes (66.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34316288/45929032 bytes (74.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38027264/45929032 bytes (82.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41918464/45929032 bytes (91.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45801472/45929032 bytes (99.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n",
            "\n",
            "[MoviePy] Building file video.gif with imageio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 40/41 [00:00<00:00, 102.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WJtUoz0_5A-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}