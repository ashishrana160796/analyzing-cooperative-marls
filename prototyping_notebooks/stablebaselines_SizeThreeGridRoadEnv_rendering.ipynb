{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stablebaselines_SizeThreeGridRoadEnv_rendering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing the latest stable-baselines3 library.\n",
        "# !pip install stable-baselines3\n",
        "!pip install stable-baselines3\n",
        "# Ignoring the restart runtime instruction and continue with the cell execution."
      ],
      "metadata": {
        "id": "34ag2hg60oia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf02b5a5-ef56-4659-96f3-8f554290b343"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-1.6.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.5)\n",
            "Collecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (3.2.2)\n",
            "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3) (3.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3) (2022.1)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616828 sha256=2e763a11c2b6751fa0f2507b73b93011f89b968ca9c0680536fbea7f28d94bb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "Successfully built gym\n",
            "Installing collected packages: gym, stable-baselines3\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed gym-0.21.0 stable-baselines3-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W5RN83LAqWyB"
      },
      "outputs": [],
      "source": [
        "# OpenAI gym related import statements.\n",
        "# Building a simpler environment that works with stablebaselines.\n",
        "import os\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "from gym.envs.registration import EnvSpec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of the 3x3 road network for MultiAgent RL.\n",
        "class SizeThreeGridRoadEnv(gym.Env):\n",
        "    # Defining the Driving Agent with name and gas values plus package flag.\n",
        "    class DriverAgent():\n",
        "        def __init__(self, name, gas, package):\n",
        "            self.name = name\n",
        "            self.gas = gas\n",
        "            self.package = package\n",
        "\n",
        "    def __init__(self):\n",
        "        # super(SizeThreeGridRoadEnv, self).__init__()\n",
        "        # Defining different possible world configurations.\n",
        "        self.world_one = np.array([[1, 0, 0],\n",
        "                      [3, 0, 2],\n",
        "                      [0, 0, 4]])\n",
        "        self.world_two = np.rot90(self.world_one)\n",
        "        self.world_three = np.rot90(self.world_two)\n",
        "        self.world_four = np.rot90(self.world_three)\n",
        "        # Even the initial world configuration is defined to be different upon\n",
        "        # environment instantiation. \n",
        "        prob = random.uniform(0, 1)\n",
        "        # Default value assignment below.\n",
        "        self.world = self.world_one\n",
        "        if prob > 0.25 and prob <= 0.25:\n",
        "            self.world = self.world_two\n",
        "        elif prob > 0.5 and prob <= 0.75:\n",
        "            self.world = self.world_three\n",
        "        elif prob > 0.75 and prob <= 1:\n",
        "            self.world = self.world_four\n",
        "        self.world_start = self.world # This 'world_start', if reset() is called, never gets used.\n",
        "        # Adding five actions for the environment.\n",
        "        # 0: up, 1: right, 2: down, 3: left, 4: stay/pass chance, 5: drop\n",
        "        # When agent reaches at package location it automatically picks up the package.\n",
        "        self.action_space = spaces.Discrete(6)\n",
        "        shape_0 = np.size(self.world_start, 0)\n",
        "        shape_1 = np.size(self.world_start, 1)\n",
        "        self.observation_space = spaces.Box(low=0,\n",
        "                                            high=4,\n",
        "                                            shape=(shape_0 + 1, shape_1),\n",
        "                                            dtype=np.int16)\n",
        "        self.reward_range = (-10, 1)\n",
        "        self.current_episode = 0\n",
        "        self.success_episode = []\n",
        "        # Defining the driver agents in the environment.\n",
        "        self.agent_one = self.DriverAgent(1,4,0) # 3 integer value, when carrying package.\n",
        "        self.agent_two = self.DriverAgent(2,4,0) # 3 integer value, when carrying package.\n",
        "        self.spec = EnvSpec(\"SizeThreeGridRoadEnv-v0\") # snippet taken from: gym/tests/testing_env.py \n",
        "\n",
        "    def reset(self):\n",
        "        # Game like formulation, each player agent moves one step at a time.\n",
        "        self.agent_one = self.DriverAgent(1,4,0) # Instantiating agent 1 again.\n",
        "        self.agent_two = self.DriverAgent(2,4,0) # Instantiating agent 2 again.\n",
        "        self.current_player = self.agent_one\n",
        "        # 'P' means the game is playable, 'W' means delivered, 'L' means no delivery.\n",
        "        self.state = 'P'\n",
        "        self.current_step = 0\n",
        "        self.max_step = 30 # agent can choose not move as an alternate choice.\n",
        "        # Selecting a world at random to function with.\n",
        "        # Even the initial world configuration should be different.\n",
        "        prob = random.uniform(0, 1)\n",
        "        if prob > 0.25 and prob <= 0.25:\n",
        "            self.world_start = self.world_two\n",
        "        elif prob > 0.5 and prob <= 0.75:\n",
        "            self.world_start = self.world_three\n",
        "        elif prob > 0.75 and prob <= 1:\n",
        "            self.world_start = self.world_four\n",
        "        elif prob < 0.25:\n",
        "            self.world_start = self.world_one\n",
        "        self.world = np.copy(self.world_start) # The self.world can be different from intial world.\n",
        "        # no exploration_prize and bonus_reward as per my design.\n",
        "        return self._next_observation()\n",
        "    \n",
        "    def _next_observation(self):\n",
        "        obs = self.world\n",
        "        data_to_add = [0] * np.size(self.world, 1)\n",
        "        data_to_add[0] = self.current_player.name # adding current player's label in the observation.\n",
        "        obs = np.append(obs, [data_to_add], axis=0)\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        # Agent's name is matched to the array entries for index identification.\n",
        "        # 'current_player.name' should be updated alongside the array values.\n",
        "        current_pos = np.where(self.world == self.current_player.name)\n",
        "        # the current agent must have gas in it.\n",
        "        if self.current_player.gas > 0:\n",
        "            if action == 0:\n",
        "                next_pos = (current_pos[0] - 1, current_pos[1]) # Agent moving upwards.\n",
        "\n",
        "                if next_pos[0] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 1:\n",
        "                next_pos = (current_pos[0], current_pos[1] + 1)\n",
        "                limit = np.size(self.world, 1)\n",
        "\n",
        "                if next_pos[1] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 2:\n",
        "                next_pos = (current_pos[0] + 1, current_pos[1])\n",
        "                limit = np.size(self.world, 0)\n",
        "\n",
        "                if next_pos[0] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            elif action == 3:\n",
        "                next_pos = (current_pos[0], current_pos[1] - 1)\n",
        "\n",
        "                if next_pos[1] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] >= 0 and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            # Newly added logic based on three new possible actions.\n",
        "            elif action == 4:\n",
        "                pass # Corresponding agent selects to not move at their chance.\n",
        "            elif action == 5: # If agent is over the package, it has to pick it up.\n",
        "                # Agent can choose to drop the package, if it is loaded with it.\n",
        "                # After, dropping the package the agent should dissappear.\n",
        "                if self.current_player.package == 3:\n",
        "                    if self.world[current_pos] == 0:\n",
        "                        self.world[current_pos] = 3\n",
        "                        # agent dissappears from the grid after this drop.\n",
        "                    elif self.world[current_pos] == 4: # Added as extra case, functionally shouldn't be triggered.\n",
        "                        self.world[current_pos] = self.current_player.name\n",
        "                        self.state = 'W'\n",
        "        else:\n",
        "            # Player 1's gas is supposed to go empty first.\n",
        "            # Therefore, upon having empty gas tank player should be allowed to\n",
        "            # drop the package in the environment and disappear from the location.\n",
        "            if self.current_player.package == 3:\n",
        "                self.world[current_pos] = self.current_player.package\n",
        "                # agent dissappears from the grid after this drop.\n",
        "            else:\n",
        "                self.world[current_pos] = 0 # If gas is finished, agent should dissappear.\n",
        "\n",
        "        # If gas is empty for both agents, the episode should stop at that instant.\n",
        "        if self.agent_one.gas == 0 and self.agent_two.gas == 0:\n",
        "            self.state = 'L'\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self._take_action(action)\n",
        "        self.current_step += 1\n",
        "        # Uncomment the below statement out, while debugging.\n",
        "        # print(self.world) \n",
        "\n",
        "        if self.state == \"W\":\n",
        "            reward = 1\n",
        "            done = True\n",
        "        elif self.state == 'L':\n",
        "            reward = -10\n",
        "            done = True\n",
        "        elif self.state == 'P':\n",
        "            reward = 0 # sparse reward encoding, only rewarded when episode ends.\n",
        "            done = False\n",
        "\n",
        "        if self.current_step >= self.max_step:\n",
        "            print(f'New episode number {self.current_episode + 1}')\n",
        "            done = True\n",
        "\n",
        "        # agents object used to identify agent properties.\n",
        "        if self.current_player.name == 1:\n",
        "            self.current_player = self.agent_two\n",
        "        elif self.current_player.name == 2:\n",
        "            self.current_player = self.agent_one\n",
        "\n",
        "        if done:\n",
        "            self.render_episode(self.state)\n",
        "            self.current_episode += 1\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, done, {'state': self.state}\n",
        "\n",
        "    def render_episode(self, win_or_lose):\n",
        "        # Storing the rendered episodes in a file.\n",
        "        self.success_episode.append(\n",
        "            'Success' if win_or_lose == 'W' else 'Failure')\n",
        "        file = open('render.txt', 'a')\n",
        "        file.write('----------------------------\\n')\n",
        "        file.write(f'Episode number {self.current_episode}\\n')\n",
        "        file.write(\n",
        "            f'{self.success_episode[-1]} in {self.current_step} steps\\n')\n",
        "        file.close()"
      ],
      "metadata": {
        "id": "8Okx4ARl5Kse"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: The 3x3 road network environment doesn't rotate in its simple\n",
        "# setting implementation.\n",
        "# Implementation of the Simple 3x3 road network for MultiAgent RL.\n",
        "class SizeThreeSimpleGridRoadEnv(gym.Env):\n",
        "    # Defining the Driving Agent with name and gas values plus package flag.\n",
        "    class DriverAgent():\n",
        "        def __init__(self, name, gas, package):\n",
        "            self.name = name\n",
        "            self.gas = gas\n",
        "            self.package = package\n",
        "\n",
        "    def __init__(self):\n",
        "        # super(SizeThreeSimpleGridRoadEnv, self).__init__()\n",
        "        # Defining different possible world configurations.\n",
        "        self.world_one = np.array([[1, 0, 0],\n",
        "                      [3, 0, 2],\n",
        "                      [0, 0, 4]])\n",
        "        # self.world_two = np.rot90(self.world_one)\n",
        "        # self.world_three = np.rot90(self.world_two)\n",
        "        # self.world_four = np.rot90(self.world_three)\n",
        "        # Even the initial world configuration is defined to be different upon\n",
        "        # environment instantiation. \n",
        "        # prob = random.uniform(0, 1)\n",
        "        # Default value assignment below.\n",
        "        self.world = self.world_one\n",
        "        # if prob > 0.25 and prob <= 0.25:\n",
        "        #     self.world = self.world_two\n",
        "        # elif prob > 0.5 and prob <= 0.75:\n",
        "        #     self.world = self.world_three\n",
        "        # elif prob > 0.75 and prob <= 1:\n",
        "        #     self.world = self.world_four\n",
        "        self.world_start = self.world # This 'world_start', if reset() is called, never gets used.\n",
        "        # Adding five actions for the environment.\n",
        "        # 0: up, 1: right, 2: down, 3: left, 4: stay/pass chance, 5: drop\n",
        "        # When agent reaches at package location it automatically picks up the package.\n",
        "        self.action_space = spaces.Discrete(6)\n",
        "        shape_0 = np.size(self.world_start, 0)\n",
        "        shape_1 = np.size(self.world_start, 1)\n",
        "        self.observation_space = spaces.Box(low=0,\n",
        "                                            high=4,\n",
        "                                            shape=(shape_0 + 1, shape_1),\n",
        "                                            dtype=np.int16)\n",
        "        self.reward_range = (-10, 1)\n",
        "        self.current_episode = 0\n",
        "        self.success_episode = []\n",
        "        # Defining the driver agents in the environment.\n",
        "        self.agent_one = self.DriverAgent(1,4,0) # 3 integer value, when carrying package.\n",
        "        self.agent_two = self.DriverAgent(2,4,0) # 3 integer value, when carrying package.\n",
        "        self.spec = EnvSpec(\"SizeThreeSimpleGridRoadEnv-v0\")\n",
        "\n",
        "    def reset(self):\n",
        "        # Game like formulation, each player agent moves one step at a time.\n",
        "        self.agent_one = self.DriverAgent(1,4,0) # Instantiating agent 1 again.\n",
        "        self.agent_two = self.DriverAgent(2,4,0) # Instantiating agent 2 again.\n",
        "        self.current_player = self.agent_one\n",
        "        # 'P' means the game is playable, 'W' means delivered, 'L' means no delivery.\n",
        "        self.state = 'P'\n",
        "        self.current_step = 0\n",
        "        self.max_step = 30 # agent can choose not move as an alternate choice.\n",
        "        # Selecting a world at random to function with.\n",
        "        # Even the initial world configuration should be different.\n",
        "        # prob = random.uniform(0, 1)\n",
        "        # if prob > 0.25 and prob <= 0.25:\n",
        "        #     self.world_start = self.world_two\n",
        "        # elif prob > 0.5 and prob <= 0.75:\n",
        "        #     self.world_start = self.world_three\n",
        "        # elif prob > 0.75 and prob <= 1:\n",
        "        #     self.world_start = self.world_four\n",
        "        # elif prob < 0.25:\n",
        "        #     self.world_start = self.world_one\n",
        "        self.world_start = self.world_one    \n",
        "        self.world = np.copy(self.world_start) # The self.world can be different from intial world.\n",
        "        # no exploration_prize and bonus_reward as per my design.\n",
        "        return self._next_observation()\n",
        "    \n",
        "    def _next_observation(self):\n",
        "        obs = self.world\n",
        "        data_to_add = [0] * np.size(self.world, 1)\n",
        "        data_to_add[0] = self.current_player.name # adding current player's label in the observation.\n",
        "        obs = np.append(obs, [data_to_add], axis=0)\n",
        "        # Observation Sample provided below for reference:\n",
        "        # last row, represents 'data_to_add' vector.\n",
        "        # array([[1, 0, 0],\n",
        "        #         [3, 0, 2],\n",
        "        #         [0, 0, 4],\n",
        "        #         [1, 0, 0]])\n",
        "        return obs\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        # Agent's name is matched to the array entries for index identification.\n",
        "        # 'current_player.name' should be updated alongside the array values.\n",
        "        current_pos = np.where(self.world == self.current_player.name)\n",
        "        # the current agent must have gas in it.\n",
        "        if self.current_player.gas > 0:\n",
        "            if action == 0:\n",
        "                next_pos = (current_pos[0] - 1, current_pos[1]) # Agent moving upwards.\n",
        "\n",
        "                if next_pos[0] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 1:\n",
        "                next_pos = (current_pos[0], current_pos[1] + 1)\n",
        "                limit = np.size(self.world, 1)\n",
        "\n",
        "                if next_pos[1] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 2:\n",
        "                next_pos = (current_pos[0] + 1, current_pos[1])\n",
        "                limit = np.size(self.world, 0)\n",
        "\n",
        "                if next_pos[0] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            elif action == 3:\n",
        "                next_pos = (current_pos[0], current_pos[1] - 1)\n",
        "\n",
        "                if next_pos[1] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] >= 0 and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            # Newly added logic based on three new possible actions.\n",
        "            elif action == 4:\n",
        "                pass # Corresponding agent selects to not move at their chance.\n",
        "            elif action == 5: # If agent is over the package, it has to pick it up, environment cases encoded above.\n",
        "                # Agent can choose to drop the package, if it is loaded with it.\n",
        "                # After, dropping the package the agent should dissappear.\n",
        "                if self.current_player.package == 3:\n",
        "                    if self.world[current_pos] == 0:\n",
        "                        self.world[current_pos] = 3\n",
        "                        # agent dissappears from the grid after this drop.\n",
        "                    elif self.world[current_pos] == 4: # Added as extra case, functionally possibly won't be triggered.\n",
        "                        self.world[current_pos] = self.current_player.name\n",
        "                        self.state = 'W'\n",
        "        else:\n",
        "            # Player 1's gas is supposed to go empty first.\n",
        "            # Therefore, upon having empty gas tank player should be allowed to\n",
        "            # drop the package in the environment and disappear from the location.\n",
        "            if self.current_player.package == 3:\n",
        "                self.world[current_pos] = self.current_player.package\n",
        "                # agent dissappears from the grid after this drop.\n",
        "            else:\n",
        "                self.world[current_pos] = 0 # If gas is finished, agent should dissappear.\n",
        "\n",
        "        # If gas is empty for both agents, the episode should stop at that instant.\n",
        "        if self.agent_one.gas == 0 and self.agent_two.gas == 0:\n",
        "            self.state = 'L'\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self._take_action(action)\n",
        "        self.current_step += 1\n",
        "        # Uncomment the below statement out, while debugging.\n",
        "        # print(self.world) \n",
        "\n",
        "        if self.state == \"W\":\n",
        "            reward = 1\n",
        "            done = True\n",
        "        elif self.state == 'L':\n",
        "            reward = -10\n",
        "            done = True\n",
        "        elif self.state == 'P':\n",
        "            reward = 0 # sparse reward encoding, only rewarded when episode ends.\n",
        "            done = False\n",
        "\n",
        "        if self.current_step >= self.max_step:\n",
        "            print(f'New episode number {self.current_episode + 1}')\n",
        "            done = True\n",
        "\n",
        "        # agents object used to identify agent properties.\n",
        "        if self.current_player.name == 1:\n",
        "            self.current_player = self.agent_two\n",
        "        elif self.current_player.name == 2:\n",
        "            self.current_player = self.agent_one\n",
        "\n",
        "        if done:\n",
        "            self.render_episode(self.state)\n",
        "            self.current_episode += 1\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, done, {'state': self.state}\n",
        "\n",
        "    def render_episode(self, win_or_lose):\n",
        "        # Storing the rendered episodes in a file.\n",
        "        self.success_episode.append(\n",
        "            'Success' if win_or_lose == 'W' else 'Failure')\n",
        "        file = open('render.txt', 'a')\n",
        "        file.write('----------------------------\\n')\n",
        "        file.write(f'Episode number {self.current_episode}\\n')\n",
        "        file.write(\n",
        "            f'{self.success_episode[-1]} in {self.current_step} steps\\n')\n",
        "        file.close()"
      ],
      "metadata": {
        "id": "2pPscl6L7Wr8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stable_baseline3 library related import statements.\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv # it's usage produces 'spec' related error.\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv # it's usage produces 'spec' related error.\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3 import DQN\n",
        "# import numpy as np\n",
        "\n",
        "# result plotter package function\n",
        "# from stable_baselines3.common import results_plotter"
      ],
      "metadata": {
        "id": "bpbJzTgt5LcI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the environment for testing.\n",
        "env_simple = SizeThreeSimpleGridRoadEnv()\n",
        "# Logs will be saved in log_dir/monitor.csv\n",
        "# env_simple = Monitor(env_simple, log_dir)"
      ],
      "metadata": {
        "id": "LJjDiyrTkN8O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training sample environment policy for checking the env functionality.\n",
        "# callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
        "model_simple = PPO(\"MlpPolicy\", env_simple, verbose=0)\n",
        "model_simple.learn(48000)"
      ],
      "metadata": {
        "id": "dx5z0giWkOC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the environment for testing.\n",
        "env_dynamic = SizeThreeGridRoadEnv()\n",
        "# Logs will be saved in log_dir/monitor.csv\n",
        "# env_dynamic = Monitor(env_dynamic, log_dir)\n",
        "# Training sample environment policy for checking the env functionality.\n",
        "# callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
        "model_dynamic = PPO(\"MlpPolicy\", env_dynamic, verbose=0)\n",
        "model_dynamic.learn(64000)"
      ],
      "metadata": {
        "id": "vx63C5MDkOl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DQN Model Learning for Simple Road Environment Task\n",
        "del env_simple\n",
        "del env_dynamic"
      ],
      "metadata": {
        "id": "oHAGMzfMytx1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the RL model instances.\n",
        "print(model_simple)\n",
        "print(model_dynamic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nMQFv0e2mwK",
        "outputId": "cca6d8e6-d452-4cca-d1a1-3ab6231353a0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<stable_baselines3.ppo.ppo.PPO object at 0x7f3353052f50>\n",
            "<stable_baselines3.ppo.ppo.PPO object at 0x7f3352f2d110>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import colors\n",
        "\n",
        "def agent_rendering(obs_list):\n",
        "    fps = 2\n",
        "    nSeconds = 20\n",
        "    # matching the dimension dimension of the obs_list with 'nSeconds*fps' values.\n",
        "    snapshots = obs_list # [ np.random.rand(3,3) for _ in range(nSeconds*fps) ]\n",
        "\n",
        "    # First set up the figure, the axis, and the plot element we want to animate\n",
        "    fig = plt.figure( figsize=(3,4) )\n",
        "    colormap = colors.ListedColormap([\"lightsteelblue\", \"chocolate\", \"tomato\", \"navajowhite\", \"yellowgreen\", \"lightpink\"])\n",
        "    bounds = [0,1,2,3,4,5]\n",
        "    norm = colors.BoundaryNorm(bounds, colormap.N)\n",
        "    a = snapshots[0]\n",
        "    im = plt.imshow(a, cmap=colormap, norm=norm)\n",
        "    def animate_func(i):\n",
        "        if i % fps == 0:\n",
        "            print( '.', end ='' )\n",
        "        im.set_array(snapshots[i])\n",
        "        return [im]\n",
        "    anim = animation.FuncAnimation(\n",
        "                               fig, \n",
        "                               animate_func, \n",
        "                               frames = nSeconds * fps,\n",
        "                               interval = 1000 / fps, # in ms\n",
        "                               )\n",
        "    anim.save('test_anim.mp4', fps=fps, extra_args=['-vcodec', 'libx264'])\n",
        "    print('Done!')"
      ],
      "metadata": {
        "id": "zsOIKNWa6O6y"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing obs data into simple road env for ppo algorithm.\n",
        "ppo_simple_obs_list = []\n",
        "env_simple = SizeThreeSimpleGridRoadEnv()\n",
        "result_test = []\n",
        "obs = env_simple.reset()\n",
        "for i in range(200):\n",
        "    action, _states = model_simple.predict(obs)\n",
        "    obs, reward, done, info = env_simple.step(action)\n",
        "    # print(info)\n",
        "    ppo_simple_obs_list.append(obs)\n",
        "    if done:\n",
        "        result_test.append(info['state'])\n",
        "\n",
        "# Printing the output results w/ successful completions.\n",
        "result_stat = result_test.count('W') / len(result_test)\n",
        "print(f'Success rate: {result_stat * 100} %')"
      ],
      "metadata": {
        "id": "GcOzl_0Tw_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_rendering(ppo_simple_obs_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "igdSxCaE5M7o",
        "outputId": "77b69314-59a4-4fe7-d79f-f5f91882ab0f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".....................Done!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "save_path = \"/content/videos/result.mp4\"\n",
        "# Compressed video path\n",
        "compressed_path = \"test_anim.mp4\"\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=175 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "2A3yGVZ_3B8v",
        "outputId": "fa0190e5-ad41-4416-c459-524a63ab8c51"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=175 controls>\n",
              "      <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAF0ltZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTIgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAocZYiEABX//vfJ78Cm61tbtb+Tz0j8LLc+wio/blsULR/xst0qCTP2LkKub6ZgzJPnnyasr1NS05wG5Xib+zc2suFhSiLWvsUGt7o8o/VZR3vvKYc+Ubtzd3e88J0hn36/8HK8hYpc6FLkFK/y2uppdxPZxOKiax9DUunceWaIQX8vY8EmCzemaxiHZXDextOB9LvODRUapXYQsQD2T6E/UMD+dy5y/hP0j7qqy84Ssfkro3TLB9ZsIfzrQ1MWZIoup56LqP2QY2/FLIMoXAap7vD2gB0U3eYHlqIGOlRl8YRzVYd5yeLvAHT9q3H8PhpiogPd718FTU0fE4WlrzwOd/RoLhci49oAei0r+8/LXGOztqd3rFufa5jVIJ4szDAMKxWEuTUup4nV0T6k6bl6D8cZZI2yKa8IMyYjKQ7EFQv0hhvIq80I8gMk7sO44ocEhqYuZvefOkwuELEpWFhBfycDYFFmdnJYi/V3daDqv/t2UGUi0BQ7e35Ps8Ikjqwxwv+N2/EMWTvyESCS98BSsZLdU20DgcQRa1i6chN6N3sigfsc05P/bgUfsM04m8ufDAHaKEG6kruormtr8Ax4DblywYF1zNgIOXCgpxKT03JjN90Ru9JFSbrf2rP26jWAqWHOQOImo7vt/utRYxPpvht6JrksZj6vZKwcBhIbyGczJDyleBeeaqJVauXqpWnW5ysr0t+zcsMsyNSyf9KGBP+yF+Gsc+JX5WqK4CMdoyoDF6DxMkanLErHqIySIimYqNnQvJVpIEWA/emf4IdBI0n2ObJvKhm9n20nJokSivQ43nV2/zzM8Eq7eIBA4gAni4bnw6eoR6rluNQxy2Zg5CM0jL1zyVHFWh8KalI8hRZdYv8ceHGHJAFfJJ9z8mhGot+oH/WB/BXk3vdVsS2/ppq9kgLyXlvFOQWwOtgDXv2jhLqA9SfnGZB3roGNxZU+2c9k/8lgAX5YpsXY53sC6UvqYvJYL4TZ7DSGKaMjbyxyg3My8QKJ6XEHv3sYoPNaJkfdky5jHaTY8Kd5IsmeugOh5YLeFIm1U50Hpx2ltD/TQc05Gy3d4lr+M3I55/Q4t0/0E+y2tBOL/6OQOtmXow+0/x6lKy2Lz1CQHk2cmNm0FwKZd6jdGzB+l9fuLhf1t58mrivnelZ/vTgWNxQ9wYCJm7loNbnjWMIvxdycyUBrOoMyIXyttje0vmpbf09MBt+/J2dNtPFYKPs+9q1Aor55ynQhIISZfJbzWizVmls7/ZuUwG0MFRC8orJlF5Ec+ADe4tpzpiIlVF4qzpZZRon0VSUoaLicXjIyh0k9Z/SLp8klrHyEON2ehwq3JuVDyfh1R26ssS9fu43v9FyQbQjQX2Im0OLJ3awaMCl8NUC+Z162HmUTNOeXp67UskkgKmwv6DVbgUwAqXF6euHNzaRsanlyT89pB1Lz8j1YSGFu6oMYJFlOinaNFNk3TWRCVvH++3Cb0jfURw4wQrkY9wyLbJ+pEJ3i35unOuYBOYrt4tqKuXyRVTJsqB4i3CB1veBO3rE6BMvmclC2WZUN7aDm8wQIXrCB7qdh2JThXyvJ4gKHBk/SAN3I18J5FMPOERV6eoACygjruEFTNmzUznP7N6ytr7pMk2Y6CiUaaCi6XriSyyix5/Vnv07cKfFWalXgJa9rfqPVoxlnf8n3IzS7YS4+f/GDNYpN4yBi+MTECz6u6O4epnS8+YRPO/J6D//wN+Nkr4GgArEFLa07TBxSE3GbvRFpE2nIoYTt0A3CFu1k7mwFHHZ7KxPqNmkV1WhWk+X/ep9IDflMIhz3YaTowqfRhwKt/2e+Q51cGlYBkG2R2b7cNjXx0QaSZIksBlpvgAnZtRpp/IzX/6fiMwRQfgQX3+v9N+TliFrS9KHb0L0isso3SPlH6o3+b1xSf98xmvanN6j1grw+ta4OBGH9CuhjMKd42f11n/4/27lzrj3Rff8Cox+9bip/l3nQcoEd+j98XAX+49N3CIUGneFfwkgtmlTMdfXoY/0X0Tj3U97ZJwbJ5d4l4FuVC7YdMGkBZAaUzcvrdzkw56SQ9sqVIpeV35JZ7fK7XW32CqjBrFQpi6nvwa3mp4vgPlHPTgLWrn3ea3Xrhzp/7Ozmb1fRLJPZ3nPr2vNGS0dlkQ1j4DR2R9NCZViQEGACAXRASijc0xUubeEE7+2TDPuTwTkjjKLkoiaoJzsB8A2N03GLy4T/BmuD0DHYlO89i8b69HGt5voyJA6lN1ZMHb20QDdKP068n/bhWMrimC1GPaZS3d1vPTvXFJLUYAPFBpnvEh1fQmxbgSdDl7fqUCN+JqwALvRdJ24fR6zCcs1EwIN0ZYgkCvVBFcQHJgHFDHfFlIQtSjV2367mr6mGQutZeU899TShy93Wwdor3oxhDHYG+3RMbTgJgCHqP2IwSR8tt4dgz+eug4u7AdUkt9pIKBEQd+d8d1ZPbt9cGnW8bRKib5QS63ow/06PDdh2ZqG6j+nmbpW/MKHHQssDN2eLjUf7OXAhJqqpn/B1/1DEUfJsZaLGaF/P/NJUZE3hZEJRPtD9J0x7JuO2qiMQLrJFC5uB5Sg50lLJwUe32DQzEkC7KRUMa0UzvoZeRY0nY0Zr+Iwc0Dk8nUrT8A+7Faqsg3Rc7Wd4ML52LBCRdQ7JfdDYJgGj3aez+h2ug/oTm2MFah0n/asq1RxbXu8acDziISIChCh2UQUxRuju+Xo+qY+bGdqSy17eMbeeREgR2jANp3uGJR/CCl4da//GzmF8wmoGkHM3U3mpi2GMLNk/XWVK5BczsgG01yuroluJrmE2OAl1Zleef8FC88wydmknsU2WUyzwpVnaDE54taef3Eb52Dw0dkVPhxBohZOzyU5jDBcYywgc9K9ApbMOdA1jCgzSB8Nm3BrlSdnTTSEGlvN99fh9e9mb5ikVJvNdbknz09Uyl0elAeFH9s4esEtufL1AeV//kxJMIuV8QugS5ZA9Uua+2AhTLAWF7XS4EJFOkjfn5bZE/8JntR3jE8IdZCbQ73RaK2LuplgThk55om8sTukmOFhAhQX+RYEN9yiea3kWFk4aMqw4St8R3oZiNsVIONPS8TsFLmxQeGbM5FpjSYJ0tEvqz1UxsoMsWdlT0lBbfriG6xdHjfOgD0FhorV24Yl8vnEpD4ctap5kJS3h52b0VvazS85Les4fD3zsca77o+qwQbcn3yiMtDDKm8FqU5SRtlsyyxl08KYc40IfoDoTFC7gN1ftrH4DVWdHjfjF3t0slwxkr3Mjv0LafE4gBOnxa1Hg4uELOqVZ34iMNaAOxv8kVV/fCN30sdwdXtMkqLp30UBhzYZn2qPOO6wZwAbsn3rn5vzQiuJ4kUS78pXHkSaczJ2x9Zp0wzDr0Uthn2nXaVqpAhyX+2U2i1vncjQDKd/nwouX1atFkAgPJCmuaSdqyM4AAQUAAAElQZohbEFf/talUHt9QkAH86ZWOASbOrVgwaqb+cIJJWcFIpvptqJ4DG8K5dB327dmoObZWzE4vexobowQ+1X+Y37d2/KzjJ2tb+Ix9tkV+/CurF8NlHzvNkq6LklHhm3qwydjeQSgzjChjtwi3dVy2bIheBl3B9oLL/7xIU/cQuyzyU4nQZ0aeGW2AyZ2EfODmh6/bUfaKw+IRRrlTJBULRS/iAKdf9nt6PcDec2QZuzkYyXVPuTNj1BAKD4FoQaH7UApKoKjc/CHv+qUwdluHH3FHLu1i8ilueehTWZwJzbCPb4KKFbxKZ8JUWSW8w5f7D4ReOhLWxfaxQWKJ/COGSRnBCiTf5SxphRs1tazMN656oruNlH3qoMlhR2XlLwiaXr4FrUAAAA0QZpCPCGTKYQV//7WpVAANRcYotOccu9MmnYoWyT4iHVYFpwNKGBpgAzD86oDejp+YIPboQAAAEJBmmNJ4Q8mUwIK//7WpVAANRcXiAAWmIp2K340h7/RGh8f9RModP7NELCVfevWW7rACsS+SiipN6bu22Muy36aiHAAAAAtQZqESeEPJlMCCv/+1qVQADUXGKLTnHLvTJp2KFsk+Ih1WBacDShTAGuancThAAAAP0GapUnhDyZTAgr//talUAA1Fxii2ZPwiJa14RpBUGA6AMD+yTFnh5TfJXBLgA7MIx/uHYV6fv8Ol9PmeMUyHQAAAIxBmsZJ4Q8mUwIK//7WpVAAu5r8OAD73BJ2Lurn9fwCu34712U7Mcp//6YlCKW7LXFvNbkZdAXGmjlRSaq7C7kQTy76n9vja7hm9ee8CFgdsEJRe6hn8X+LGQmFip/vh46c2KhftCVLtWMFVzOkw4VlUALozuNIanf8Hm7P0OlBxLjMt0Isx9GO3hrogQAAAC9BmudJ4Q8mUwIK//7WpVAANRcYotmT8IiWteEaQVBgOgDA/skxZ4eU0c8sUhTIcQAAAPpBmwhJ4Q8mUwIK//7WpVABCHdCq8dHhPcFJp/qdZRv45/p8xIIqkLqdkPMkQcdLPOCGEcm6s8bCQLVbHKLG0dtXY0AH2XXuWRyYn0AQbVCijr1W5Zcpn4jc+yOs+oLuETZxE9xhoTQTNZAUSxcau0Ui28rjFlk28ExV0BlWj4RwoRQABgCTP8S0MpF1TFxoaFfHfJ/Z3RBbZBlUgWzhXjunKgH7yqqIPgQlMNG9ZzfrtWLhUDkxjbN1rHbKp/iBNLsXQDdAk09k9tvsv+sQXqAXUSZ4iR24HAcpUPXhsj50htQQoy+/4xhal6RFVinPIHhUb7G/lq0Ed8wAAAALkGbKUnhDyZTAgr//talUAA1Fxii2ZPwiJa14RpBUGA6AMD+yTFnh5TRzVjd2IcAAAA0QZtKSeEPJlMCCv/+1qVQAD5w0KgPiXJe15iIwH8BZK9KlYsEEP3ie9JnRd0x+PuABynyQQAAANlBm2tJ4Q8mUwIK//7WpVACI/efpLZ2lqBGBMW3rW7I/2iesQi//DWBiCSBdTx7C8QxIWV3lvwMPPRewYGCJZQVct0oNi3mZljE5PMRVkcIebutXW4oJ+hgMMPX/QQKtGQLS77pAGDDWrB1ExAQvMJdmFNWY44/8Bx/4+p8M7hJfiINv6n5N+MvQFQ8e7ZUQkHr+A5SRtMwxHP/wbr5UXmXXT0T6Y9eYoaiY0cDGLSI+SCPF/PPyQIi6PMpqK0CPiZQEBeBhRfPLA9kxPmhJyyjNTP/qa4BZVHuAAAAK0GbjEnhDyZTAgr//talUAA1Fxii05xy70yadihbJPiIdVgWnA0oUwB7yMIAAAAuQZutSeEPJlMCCv/+1qVQADUXGKLZk/CIlrXhGkFQYDoAwP7JMWeHlNHNWN3YhwAAACtBm85J4Q8mUwIK//7WpVAANRcYotOccu9MmnYoWyT4iHVYFpwNKFMAe8jDAAAALkGb70nhDyZTAgr//talUAA1Fxii2ZPwiJa14RpBUGA6AMD+yTFnh5TRzVjd2IcAAAArQZoQSeEPJlMCCv/+1qVQADUXGKLTnHLvTJp2KFsk+Ih1WBacDShTAHvIwgAAAC5BmjFJ4Q8mUwIK//7WpVAANRcYotmT8IiWteEaQVBgOgDA/skxZ4eU0c1Y3diHAAAAK0GaUknhDyZTAgr//talUAA1Fxii05xy70yadihbJPiIdVgWnA0oUwB7yMMAAAAuQZpzSeEPJlMCCv/+1qVQADUXGKLZk/CIlrXhGkFQYDoAwP7JMWeHlNHNWN3YhwAAACtBmpRJ4Q8mUwIK//7WpVAANRcYotOccu9MmnYoWyT4iHVYFpwNKFMAe8jCAAAALkGatUnhDyZTAgr//talUAA1Fxii2ZPwiJa14RpBUGA6AMD+yTFnh5TRzVjd2IcAAAArQZrWSeEPJlMCCv/+1qVQADUXGKLTnHLvTJp2KFsk+Ih1WBacDShTAHvIwgAAAC5BmvdJ4Q8mUwIK//7WpVAANRcYotmT8IiWteEaQVBgOgDA/skxZ4eU0c1Y3diHAAAAK0GbGEnhDyZTAgr//talUAA1Fxii05xy70yadihbJPiIdVgWnA0oUwB7yMMAAAAuQZs5SeEPJlMCCv/+1qVQADUXGKLZk/CIlrXhGkFQYDoAwP7JMWeHlNHNWN3YhwAAACtBm1pJ4Q8mUwIK//7WpVAANRcYotOccu9MmnYoWyT4iHVYFpwNKFMAe8jDAAAALkGbe0nhDyZTAgr//talUAA1Fxii2ZPwiJa14RpBUGA6AMD+yTFnh5TRzVjd2IcAAAArQZucSeEPJlMCCv/+1qVQADUXGKLTnHLvTJp2KFsk+Ih1WBacDShTAHvIwwAAAC5Bm71J4Q8mUwIK//7WpVAANRcYotmT8IiWteEaQVBgOgDA/skxZ4eU0c1Y3diHAAAAK0Gb3knhDyZTAgr//talUAA1Fxii05xy70yadihbJPiIdVgWnA0oUwB7yMIAAAAuQZv/SeEPJlMCCv/+1qVQADUXGKLZk/CIlrXhGkFQYDoAwP7JMWeHlNHNWN3YhwAAACtBmgBJ4Q8mUwIK//7WpVAANRcYotOccu9MmnYoWyT4iHVYFpwNKFMAe8jDAAAALkGaIUnhDyZTAgr//talUAA1Fxii2ZPwiJa14RpBUGA6AMD+yTFnh5TRzVjd2IcAAAArQZpCSeEPJlMCCv/+1qVQADUXGKLTnHLvTJp2KFsk+Ih1WBacDShTAHvIwwAAAC5BmmNJ4Q8mUwIK//7WpVAANRcYotmT8IiWteEaQVBgOgDA/skxZ4eU0c1Y3diHAAAAK0GahEnhDyZTAgp//taMsABqLM4ME7c/KVmp8if9ZiPTxGVMoqaLABFJGEEAAAAuQZqlSeEPJlMCCn/+1oywAGoszgw2xaHiWdN+mnhH6sQNmRN6bEa4v0xbubJGEQAAACtBmsZJ4Q8mUwIKf/7WjLAAaizODBO3PylZqfIn/WYj08RlTKKmiwARSRhBAAAALUGa50nhDyZTAgl//rUqgAGeoNYcfY1DliH3lWIU1nvuHfL7BctWMFJMlkfIcQAAA7ttb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAABOIAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAC5XRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAABOIAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAA2AAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAATiAAAEAAAAEAAAAAAl1tZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAAEAAAAUAAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAIIbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAByHN0YmwAAACYc3RzZAAAAAAAAAABAAAAiGF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAA2AEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAyYXZjQwFkAAz/4QAZZ2QADKzZQ4JeXhAAAAMAEAAAAwBA8UKZYAEABmjr48siwAAAABhzdHRzAAAAAAAAAAEAAAAoAAAgAAAAABRzdHNzAAAAAAAAAAEAAAABAAAAGGN0dHMAAAAAAAAAAQAAACgAAEAAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAoAAAAAQAAALRzdHN6AAAAAAAAAAAAAAAoAAAM0QAAASkAAAA4AAAARgAAADEAAABDAAAAkAAAADMAAAD+AAAAMgAAADgAAADdAAAALwAAADIAAAAvAAAAMgAAAC8AAAAyAAAALwAAADIAAAAvAAAAMgAAAC8AAAAyAAAALwAAADIAAAAvAAAAMgAAAC8AAAAyAAAALwAAADIAAAAvAAAAMgAAAC8AAAAyAAAALwAAADIAAAAvAAAAMQAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing obs data into road env for ppo algorithm.\n",
        "ppo_dynamic_obs_list = []\n",
        "env_dynamic = SizeThreeGridRoadEnv()\n",
        "result_test = []\n",
        "obs = env_dynamic.reset()\n",
        "for i in range(200):\n",
        "    action, _states = model_dynamic.predict(obs)\n",
        "    obs, reward, done, info = env_dynamic.step(action)\n",
        "    # print(info)\n",
        "    ppo_dynamic_obs_list.append(obs)\n",
        "    if done:\n",
        "        result_test.append(info['state'])\n",
        "\n",
        "# Printing the output results w/ successful completions.\n",
        "result_stat = result_test.count('W') / len(result_test)\n",
        "print(f'Success rate: {result_stat * 100} %')"
      ],
      "metadata": {
        "id": "525Xnw-D8hTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_rendering(ppo_dynamic_obs_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "risO6a008hgY",
        "outputId": "024f8aa3-2078-4830-d808-4bf7f8ecbf0f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".....................Done!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "save_path = \"/content/videos/result.mp4\"\n",
        "# Compressed video path\n",
        "compressed_path = \"test_anim.mp4\"\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=175 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ThwPmwr23CIs",
        "outputId": "00dec7d8-6f74-4afb-e3e4-3a43b18286b9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=175 controls>\n",
              "      <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAHRZtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTIgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAArHZYiEABX//vfJ78Cm61tbtb+Tz0j8LLc+wio/blsULR/xst0qCTP2LkKub6ZgzJPnnyasr1NS05wG5Xib+zc2suFhSiLWvsUGt7o8o/VZR3vvKYc+Ubtzd3e88J0hn36/8HK8hYpc6FLkFK/y2uppdxPZxOKiax9DUunceWaIQX8vY8EmCzemaxiHZXDextOB9LvODRUapXYQsQD2T6E/UMD+dy5y/hP0j7qqy84Ssfkro3TLB9ZsIfzrQ1MWZIoup56YjS9id/9DBwSE6ywqDBoIeX/I0cx4W+bdXflFBfpc+NQIa3Mm54k8+eHlsxRtaChvcXswifhP28QAIck9yJbfuW6y5WxPUTDlc+DHd1xpf40P40cpWAYV0RX5ZE7JT1Bs0DAbn21Wwcm4nyV0l79mhjhwPfV87FvyY7cp/ixA2A78epaXewQ1qjqzDKdW/T2mMb1J+bDuk91NzcY//lygjH8QPONa1PlIfn0kMwd3SajfN8VmyQMliEqD7ti+4EzqzEMaOHNGyh7JFR8Jao5wtVng1IVKsBL+5lKC3xAF5AjygqiDradrYocEjHwKvP80XkFO1E/IeCX4RWckCbyXnOrfRcULcsI+7N6nOnk7CYFS+N5MAA0C3r294vqZ4QVLOsrJRIVD9JNuN0C09c1y7wrR7UPYz65hh9RZha7c38+G5WRPIWVdfgzwk1eS1/IMuzBC0n5x0/XCZwD0Ec9f9O8o2FIRm9tmwRqgR/7ZjzVZ7Hqe/2z/VE/vXegMkDxbeftpRiXc55yr9wt4Gp90kJg9+NoTQfczzV5eNxzC2RLJPvQjxcW6QUQ0S0CLFtJvGiS//ez//5vMhl4SvwaeT6+zieMYpa1kh6kkRAnAQcGBgiPePB9GT7d0YRRTEHKmuFe4n2SY5LhnEe3jCZL/OxInWDQKWqnJPICkvPz6xcerLIb7eJH7Cn3xBeszPy3LwFFcrCalCZxtr5kZD3PAObbLNSkfwxPBlBprhpvS7JD1GkUWWkTblnP19SbRGRDtprNPeTFYeL7HF5XhIrxcGDpFXPz7i5QX29k/+7T4H96QCO3RRFvS9j8Fmx9kQme0CuNi+4qicm9JPDMRV/dbt+bsgWzW9dq0S3lD3IB4qXw73hQgHdwJWHuV4mD0wjzPWjaSXlTiHAT0A14XPDgGRz/P+/PCB1Rx2Q+bJ/JKE5GcjSFh7QZ2DuzEUA2vaHSA3efgFz9xcL+tvPk1cV88Ds5L5K9yvg7kXHb5BFD6pNg+wwi/F3JzJQGtNeT5apxublbP4arlpcRrXMSU1CRUFMXgjqBJ0EFXHySsW9d4Tp707EY4qkBl+Ddi6sNbl97kLX+ciwUsBrrgAFi+iMqUbulUrH8svf+FkVUMf2SW2l8TgCvN6HcWPFwpTLKokIN3nFxjRvQmxLUg1YrK0wmd3WgK/uahPRxCSj3Rsfz+iBcV4BnwGawQB8fUj3wWx5dMbYBEaTdGMTQ7biaDuTuCLcWizySH6Y2npcJAjKzSYflGPIbU8KAvDWrxXg4iX6oVJKKXM/N93RmxK/IrSSA9Du93OOcynIN0laYff367imHm/Iz3ylAnDRgSs4kezsD//9ZL0sfXH3vU/bj/49Yavtsn8VDh6tc2BAfqNuOdvyC0SGTg6j8Ix6jLXRqBuxi7hck8r4JUGfXtaGLejDuzqyWyYWBXUvaWs+0YyNQASHvTJL9AaNsIRGfTaSetkwh6lCTiz5mlx+gi3oA+Xxhm5YPjRVVuXgTUJOBVO9uqtHThaFdT0BS+dUG1hlugvyoWieT8vioQI8If6U3uTWaGdAGV2wsZS6+mnr7TrowmuhemTsIJxP/s7dIV9oX4bot6j2u54Tr3WxvRvQ0H/frZMBvIi4DTp8I1UhfcKYRhmzCUVv6zHDrrIlRICpiQOyfJYxEvHDyCxS2V85AVTfZjIZ6D5EG3erD6231R4JA4/QXIL70H6k34+uYc9JIe2VOT7375q2ixT3BTvLrc2F1E8kwc+1N5nMWeGCZlXZEfnfyi9Txe+SNzdzycfKmp+JrDeabJUpPpxbSKjnBwvgAnZhXlfD52IJyywbKD9f1G2zyThmoG+jLNSqNOx/ZxUB3F+oDqMlNXq7C38dvrOUbVyQvBbFVEqcmw3SNC6hqmXxLF3SL7T/hrQ+QsFKr5OfH4agilfK3YfBQwOtWsB5Xp1ElBNQVas3D7CZATJHVKwdrTxW6aQgUWq4pjQRhriZcFgu73NbntpDvyq4lQCXV8NFmOPlIgV8F8hE+AkpNV2N74r0Crf9nwKBdGjOjavOu/h/8YbZ0/9nZzN6volkns8wVhNpFRzg4XwATueRbhIzpaegsZmulC3y5Ll909xX2WaSyHQ3eCbLuu2+jr0GKNiLrx5stYZxr81PiwHzeLr8Gv++F7v2aqzHqmlRNBhIEnecZSb2JkHTYdF5EkNuVzsBgH+WTUSvuN5BwvceelopPtLXcqdN9iCCYJDv+w7KGaL5p3/qL4jKpGtaazaAPXFUTyzkqqwuen//1n02XaIO1lTnWeAThTSE5IVSLTmzL+GKOY735uhUmghlEklIehWtB38k8o6ENonqVvKF5lV4P1/s6SlaXfubDPADC+mfqyP9G7ShWUM0S0ei0kdF2muEtyPfIEBfntya0gq+szLZwO0mEl9o+z26Ab4iS465ruQYMlaE6khbqVQNqtkBWtaXIKGHagcHbbbsuUI3F7IZMVLPFuGSVZd9Pk48NzmWvUIUUVXBvk8/bG5q/GKlmvE7RsfJUDOjf1lzEc2bNcMDYeQRSfx+Nkd7kFOPOgIwjQ9AWftBzNFhqVR901lgA75QRlBPF3EA6lYKrjb8Zjapt4sC2nHJcmt50NGn4p/NuAgb84lXn4RyOYP1VfgkPg0/1ShOfkP02A+sXHanwJ7E/+fQvc0/xxK8DqujM7LHYMcHwmOWZ/V8IN8fYMwXnhGK0QRaFuQtnyYlZpfRnVr/uHqcbOZ8wNKgUspqGeCxGwXPVaQnKmLox53M7IBtNcrgfv4RfScOFO1Zyjn4vK5/R/OXTTo1y8JpkTmtZgAg/v09sS83uLczECMiis390j/Y6DgT4vD5M4iwCief15H2EN/7xwvAN6g+GfnQ4T4aiF3Y9OS28MSx/c1tJ8mdzvoJFwtLHO69t2XrMSXBF/Wlegk7NJ/IlJUEt+gjiIU2j8Vmkwcm2oVdx801yhO99DoqVT/73//rB6/7AcQGeKqUi1wiVE7M27i9NnR0BEIjf/dCYreOgky+SYXBkX7QC/bA0iwJwyc80TeWJ3bKUSBqsHjN3vuUTzW8iwsnKdlbxbtGTQnRsOIP5hxp6XidgpkVIZBtCLgxezHTNjDSyoe7n9Y40jbvbtghls3oyQplPrC99f+9MmMp8LzzfKmJUfI3gLxWBIGF/X4P7ut5rgou6KjjxwiKV89hyVWlGKt52ZHPymAhf6E4MiLcOgXEDhQ8SpXUmXCbBw9irky2VhJnf3DHa7QJOOJ4e1IkvYq/NVOMAva5OZzl4ALkQ0DsdSM5m+UHQSfwokPbpxEqLq9eUDGmwzPtUecd1gzin8HCN1U8/wz03JxSKJd+UrjyJNOZztUHe50wzDr0Uv/w4jaaVqpAhyZDeXdhz8ncjQDKd/nwouXjXv/j7LPJCmuaJ0NYgwBC0AAAEjQZohbEFf/talUHty7f/b3HVH8XQAXVDH/L79s/P/ymYP6NkRlAww9pb7bK+xFsPNtohXBi5O4StPueRSW3aFF/3PBg+Hcba9GpiLbhwW+3rz3lp7Fv70s5yqIhaZ7b0Z9iibSeXFS5N2xgozTlcqsiQLR2wlcretUfF/n0b55x4Hu1wQF2kj9TqEYOonEs+6kPfmLsUYkmup9BmjcCAkUn18plGuecknHMelZEqVARLt40fMcLljUhOaAjLERr3RpMa0C+uISklsGOnr11HB63ovcPzWdddQMlGASm0UGcIhXBla6uil/0wRqq6JlovCO+WdnvhGM5KSrV8wC5u4cae9BJsUk72x20mOBkxH4gxRApzT+BwG50yza0BYZQpJt2mCAAABS0GaQjwhkymEFf/+1qVQliawAJ5MxKrnYJH/0jgklAWqrb5ICeyeWd/SpgRa3nL2bcgmL+KQ7DBh3V98QYkTtbW1Bf/5Bgf96qR6+EpgomihjmCW57NYgCU7KucXUiAscX7HGds7Qrg2e78wj3Dl/7QPQoxoH8gz8fQnMh9vngT261J8A0i7U5Xbuv8dfyKcb0h8XVT+jzLx7yRc18M9uxo/CTM+fHncAwpuDL7I4fVOjAWhGSLQ11Hp+agkBP476KPCHu1ZLt76sW6BD42SyPxS5Itv4181A4KPPUkAsuXW45LQ9/NA+lW6NS3xxpdHelC51gcH6PnOzZw9Xj2fCs6VUTS2hMglVdJr6KGV5gPjf4zDg6C3z/CHXnJxJv9A6HDVLdzMJYuDxLGRvPgO3Mi3/7gci+QDq3JQKl0V/JCgMoXwv3oF3oBHH0EAAABOQZpjSeEPJlMCCv/+1qVQADUXGKLTnHLvTJp2KFsk/kmCEMgkD1XdEccwAZmk2bqR/XLBJFdf79sSlL//6IhjRg5GrFT9fZ+WMdqVnYhwAAABPUGahEnhDyZTAgr//talUJV+xg2PZghol5Vv1OXEVKiyoIxR7oWL5YscpzIBH0aP7GF4sNis6THp1p2t4xLCFtMcsUqAsQP//MYDxt1PdzoHOSo8CmPfDISxv1cV4dLCsXqzi1uJmnaQD08H5xlfQIRV48sEOUstF8YBy1lP31Y2oTIWg6jri+abyUEbAAJlRzV+hL3wTZFNbxfwerFbUqyFJdEBHjFjSQfusjS48vfZvkMbINIZHlHq41wTWiPrEw0/OI8+KNhY0afjkLqB6bVI000U+RZgb1vkaGm1kX01cXA6vtBUt8j1jddY+ckiizTTZq/rULXTqyI/nShNNrGt6BLixZlSCzVCPh5KF5DQL0Kpc+J/15oPpDHhF1qUijPE3EAE4hQnA+s6Tz3T8WVN+6YFYCdksgD31nypAAAASUGapUnhDyZTAgr//talUAKXxE5QAoDoBcP7qJqhqmiMnge+AnI0jDJJPsyt67H0bbf2geEm0UTU1/F5m8rae90SR+n/lUyT5YEAAAFrQZrGSeEPJlMCCv/+1qVQApdfVQGIAGxcI1lppvMk52uBscTr+NkJ31C/IQBoF3guwhkgIIzOk9Q48NZYyfcNLK32+Xo3YF6jbn/haYowQbM7ZokMxOg6w3tVCXrOAO/ha905QVMa28GhXhKjp3wDpCHpay9zNFbKPHaH7cNv1F9pGQelraTuFpMWN/xjNkZwGDPFZea+dtcviGof/EvgLQ6vqwTew6UwzwRK89cJn7N3xtDPZYZz7KF6t8Dqy1NNs4bDoSMNRZGJaufFkXh8nWM64sm7pjO9vx4QOlOI94UzX2pLlbbpqu7FigBa+7Z6BjJooLqI7jXcCPYLZXQQ53kYI464fNrmCQCbH/dAVvaF4OwHqoH1oUAhnp1lEPSDklT+0wVg3VXRTr93J2oEGPioFCD7CKVakd83+oyF0vRYGoUdHlPBhkKXZE5S8oPX6KJSxL/MuovwHpMJslvixuc9hLMR8+K9ASrhAAAAfkGa50nhDyZTAgr//talUAA1HGuQAsSmuwTmBBhbTXYcJH+ciGbhyQYM8OOsW7nhIXdVmeaz7acNQxW1XHrNuOfhV5fEK3KuVvx/OTLcPXHGbUVLRSeiPrQPv1wTxZJ3TCURI806mwyR31iWmpuSNvFJLY2Xy1OLo+vSFxDIcQAAATBBmwhJ4Q8mUwIK//7WpVAA3nCcAA3G8HHtNOit7zUZbjHQignPWSbKE3R+FMgf6YjrKZ1NZfAsgBH6b5jAfy400KTV92N7IB/+BxkEusHFSuLJISmsXiKk30C+Iw8aoJN85Yv2JHWxdL1+JSU+gw5/WFpIKa+CY/UBfWfiRNtr21MZlFNQD8M+mG6kh6IoY4OMu2FyJEojd+DfR1mXd+NVhaZNWjx3YpjDQxO5//Qwp5yOHX6RzrzS43l92+6ozGxV3TJPXvTgMTb44T+cFeALUrplzFzI4zshUS2n+V16EmNjLw0IrN8PW6AlhBud3MwRBrt2QERd538afu8HoRXXnKFq0ofp9W3Rnin9Em2bJ1uahn/gV53kvXJT5UBVpfZ4Vc+LQOAbkY/F/VjhjQHwAAAAgEGbKUnhDyZTAgr//talUAA1HGuQAsSlHQSAJiDOWmuw9yP85EM3Djx5VNtji1k4rhCovKsvRPUI1XHwAnr1xlpZq+3oMs08WhN+vpeYEirRGQGwTdgGH+VSy/AbRxPafqxfkx5p1MNUn66xAEoVLS46Zrr35KWdaN1QFtNi2RhAAAAALEGbSknhDyZTAgr//talUAA1Fxii05xy70ybpH4SfyclV5TyhVL+WHZQvKIdAAAANkGba0nhDyZTAgr//talUAA1Fxii05xy70yadihbJPiIdVgWnA0oy2yIAMcqbN1I/sfFVuMQ4AAAACxBm4xJ4Q8mUwIK//7WpVAANRcYotOccu9Mm6R+En8nJVeU8oVS/lh2ULyiHAAAADZBm61J4Q8mUwIK//7WpVAANRcYotOccu9MmnYoWyT4iHVYFpwNKMtsiADHKmzdSP7HxVbjEOEAAAAsQZvOSeEPJlMCCv/+1qVQADUXGKLTnHLvTJukfhJ/JyVXlPKFUv5YdlC8oh0AAAA2QZvvSeEPJlMCCv/+1qVQADUXGKLTnHLvTJp2KFsk+Ih1WBacDSjLbIgAxyps3Uj+x8VW4xDhAAAAMEGaEEnhDyZTAgr//talUAA1Fxii05xy70yZDIAgky5Z/3cXdhU/nmGJ3w9+Al0jCAAAADZBmjFJ4Q8mUwIK//7WpVAANRcYotOccu9MmnYoWyT4iHVYFpwNKMtsiADHKmzdSP7HxVbjEOAAAAAsQZpSSeEPJlMCCv/+1qVQADUXGKLTnHLvTSqaIZaespi3++5icDL2OnHSxDkAAAA2QZpzSeEPJlMCCv/+1qVQADUXGKLTnHLvTJp2KFsk+Ih1WBacDSjLbIgAxyps3Uj+x8VW4xDgAAAAMEGalEnhDyZTAgr//talUAA1FxeIACJUQ3tl0uexVFxVv40XdhUu8uffunGQEVkYQAAAADZBmrVJ4Q8mUwIK//7WpVAANRcYotOccu9MmnYoWyT4iHVYFpwNKMtsiADHKmzdSP7HxVbjEOEAAAAtQZrWSeEPJlMCCv/+1qVQADUVYCCq0l8/ZgMFcYUhbJPkWtNWWnA9BHlM7ohwAAAANkGa90nhDyZTAgr//talUAA1Fxii05xy70yadihbJPiIdVgWnA0oy2yIAMcqbN1I/sfFVuMQ4QAAADRBmxhJ4Q8mUwIK//7WpVAANRcYotOccu9MmnYoWyT+bmCIk7jtfuzBF0rg5M0lbCdLuiHBAAABRUGbOUnhDyZTAgr//talUADecJwAB0t9TmQdng2Gmed0w1dps0JrYIEv9hf+mI60rWWo74v+CGnGLY5S6sSguXywShLqSF1nxJUbnlEUr+5wxB6NX+KP8IoL9YobSq1dc7V+6UzAFBesgG1I/+VwWeOaAxl/AmmQnav2AS2RlDDPLclZb34oBWH2UZN6OP7yz/rNuNelk9p88TM+4QxvfLU6tb5WrJWfVE8/8+b78z5T4Xp0dxbO63DHCK0E5Sa9V8fpNWJHPcyIzhDgh3D5hF9aAj7ITiVsXORzSjiXeqQSG1XOJqBlGforOZq1DdP/Wf5zaOC4GsJ/e0JpH+qPB6ahXEWSDUWFUQA5RBLj1US8Pj2iYNgki1bayi1sx2se6HhUDiyCcjN8tew/SI4QVqB10xFIfaGFg7ohUwysDq+LPDLePggAAABQQZtaSeEPJlMCCv/+1qVQADUca5ACMttX4PkTPvLS7lNynC8csTUJ90kRET9QKzeo8dqC3J9Ztx02ZH6qL4SOHW92AYXArnRn5XIBw73yZDkAAAA7QZt7SeEPJlMCCv/+1qVQADUXGKLFwAESnjXcEghgt4JeD/7uLvXEtdbDFTYXeWWFX3hSkf2d0JOhiHAAAAAtQZucSeEPJlMCCv/+1qVQADUzgyAsBPwi+Zm18g/6K5gppvu8DqWMhm2r15iHAAAAOUGbvUnhDyZTAgr//talUAA1FxiixcABETs13BPYqX2Gf93F3YVLvLn37p+9Ez3acBDpH9ndCz6kYQAAAC1Bm95J4Q8mUwIK//7WpVAANRcYotmT8IiA3sKixurTgg5QSVPiz62DeoYNEOAAAAA5QZv/SeEPJlMCCv/+1qVQADUXGKLFwAESnjXcE9ipfYZ/3cXdhUu8uffun70TPdpwEOkf2d0LPqRhAAAALUGaAEnhDyZTAgr//talUAA1Fxii2ZPwiIDewqLG6tOCDlBJU+LPrYN6hg0Q4QAAADlBmiFJ4Q8mUwIK//7WpVAANRcYosXAARE7NdwT2Kl9hn/dxd2FS7y59+6fvRM92nAQ6R/Z3Qs+pGEAAAAtQZpCSeEPJlMCCv/+1qVQADUXGKLZk/CIgN7Cosbq04IOUElT4s+tg3qGDRDhAAAAOUGaY0nhDyZTAgr//talUAA1FxiixcABEp413BPYqX2Gf93F3YVLvLn37p+9Ez3acBDpH9ndCz6kYQAAACxBmoRJ4Q8mUwIKf/7WjLAAaizODDbFoeICmylNfxe7+H2e7/+s4prqR+tRDwAAADlBmqVJ4Q8mUwIKf/7WjLAAaizOC8sABVgiOP/U01uD//wX+8mHXv1Cu/D3DneXfcYZmv3ryonBkOEAAAAsQZrGSeEPJlMCCn/+1oywAGoszgw2xaHiApspTX8Xu/h9nu//rOKa6kfrUQ8AAAA3QZrnSeEPJlMCCX/+tSqAAZ6g1hjBAJV0xM/LH2M+H/zw+C9thuFgKH+QiWp4GgzzMVma8hj8hwAAA7ttb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAABOIAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAC5XRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAABOIAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAA2AAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAATiAAAEAAAAEAAAAAAl1tZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAAEAAAAUAAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAIIbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAByHN0YmwAAACYc3RzZAAAAAAAAAABAAAAiGF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAA2AEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAyYXZjQwFkAAz/4QAZZ2QADKzZQ4JeXhAAAAMAEAAAAwBA8UKZYAEABmjr48siwAAAABhzdHRzAAAAAAAAAAEAAAAoAAAgAAAAABRzdHNzAAAAAAAAAAEAAAABAAAAGGN0dHMAAAAAAAAAAQAAACgAAEAAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAoAAAAAQAAALRzdHN6AAAAAAAAAAAAAAAoAAANfAAAAScAAAFPAAAAUgAAAUEAAABNAAABbwAAAIIAAAE0AAAAhAAAADAAAAA6AAAAMAAAADoAAAAwAAAAOgAAADQAAAA6AAAAMAAAADoAAAA0AAAAOgAAADEAAAA6AAAAOAAAAUkAAABUAAAAPwAAADEAAAA9AAAAMQAAAD0AAAAxAAAAPQAAADEAAAA9AAAAMAAAAD0AAAAwAAAAOwAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aZ6MbMNvA9xu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}