{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stablebaselines_SizeThreeGridRoadEnv_prototyping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing the latest stable-baselines library.\n",
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "id": "34ag2hg60oia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b469ebce-3b68-41d1-e3d5-b7213b209600"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-1.6.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 24.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.21.6)\n",
            "Collecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.12.0+cu113)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (3.2.2)\n",
            "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3) (2022.1)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616828 sha256=a6063d02315ba9ed6a066fd7af8843e506cc3bb3c2b087d4aba8a87c26e3780d\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "Successfully built gym\n",
            "Installing collected packages: gym, stable-baselines3\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed gym-0.21.0 stable-baselines3-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W5RN83LAqWyB"
      },
      "outputs": [],
      "source": [
        "# OpenAI gym related import statements.\n",
        "# Building a simpler environment that works with stablebaselines.\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of the 3x3 road network for MultiAgent RL.\n",
        "class SizeThreeGridRoadEnv(gym.Env):\n",
        "    # Defining the Driving Agent with name and gas values plus package flag.\n",
        "    class DriverAgent():\n",
        "        def __init__(self, name, gas, package):\n",
        "            self.name = name\n",
        "            self.gas = gas\n",
        "            self.package = package\n",
        "\n",
        "    def __init__(self):\n",
        "        # super(SizeThreeGridRoadEnv, self).__init__()\n",
        "        # Defining different possible world configurations.\n",
        "        self.world_one = np.array([[1, 0, 0],\n",
        "                      [3, 0, 2],\n",
        "                      [0, 0, 4]])\n",
        "        self.world_two = np.rot90(self.world_one)\n",
        "        self.world_three = np.rot90(self.world_two)\n",
        "        self.world_four = np.rot90(self.world_three)\n",
        "        # Even the initial world configuration is defined to be different upon\n",
        "        # environment instantiation. \n",
        "        prob = random.uniform(0, 1)\n",
        "        # Default value assignment below.\n",
        "        self.world = self.world_one\n",
        "        if prob > 0.25 and prob <= 0.25:\n",
        "            self.world = self.world_two\n",
        "        elif prob > 0.5 and prob <= 0.75:\n",
        "            self.world = self.world_three\n",
        "        elif prob > 0.75 and prob <= 1:\n",
        "            self.world = self.world_four\n",
        "        self.world_start = self.world # This 'world_start', if reset() is called, never gets used.\n",
        "        # Adding five actions for the environment.\n",
        "        # 0: up, 1: right, 2: down, 3: left, 4: stay/pass chance, 5: drop\n",
        "        # When agent reaches at package location it automatically picks up the package.\n",
        "        self.action_space = spaces.Discrete(6)\n",
        "        shape_0 = np.size(self.world_start, 0)\n",
        "        shape_1 = np.size(self.world_start, 1)\n",
        "        self.observation_space = spaces.Box(low=0,\n",
        "                                            high=4,\n",
        "                                            shape=(shape_0 + 1, shape_1),\n",
        "                                            dtype=np.int16)\n",
        "        self.reward_range = (-10, 1)\n",
        "        self.current_episode = 0\n",
        "        self.success_episode = []\n",
        "        # Defining the driver agents in the environment.\n",
        "        self.agent_one = self.DriverAgent(1,4,0) # 3 integer value, when carrying package.\n",
        "        self.agent_two = self.DriverAgent(2,4,0) # 3 integer value, when carrying package.\n",
        "\n",
        "    def reset(self):\n",
        "        # Game like formulation, each player agent moves one step at a time.\n",
        "        self.agent_one = self.DriverAgent(1,4,0) # Instantiating agent 1 again.\n",
        "        self.agent_two = self.DriverAgent(2,4,0) # Instantiating agent 2 again.\n",
        "        self.current_player = self.agent_one\n",
        "        # 'P' means the game is playable, 'W' means delivered, 'L' means no delivery.\n",
        "        self.state = 'P'\n",
        "        self.current_step = 0\n",
        "        self.max_step = 30 # agent can choose not move as an alternate choice.\n",
        "        # Selecting a world at random to function with.\n",
        "        # Even the initial world configuration should be different.\n",
        "        prob = random.uniform(0, 1)\n",
        "        if prob > 0.25 and prob <= 0.25:\n",
        "            self.world_start = self.world_two\n",
        "        elif prob > 0.5 and prob <= 0.75:\n",
        "            self.world_start = self.world_three\n",
        "        elif prob > 0.75 and prob <= 1:\n",
        "            self.world_start = self.world_four\n",
        "        elif prob < 0.25:\n",
        "            self.world_start = self.world_one\n",
        "        self.world = np.copy(self.world_start) # The self.world can be different from intial world.\n",
        "        # no exploration_prize and bonus_reward as per my design.\n",
        "        return self._next_observation()\n",
        "    \n",
        "    def _next_observation(self):\n",
        "        obs = self.world\n",
        "        data_to_add = [0] * np.size(self.world, 1)\n",
        "        data_to_add[0] = self.current_player.name # adding current player's label in the observation.\n",
        "        obs = np.append(obs, [data_to_add], axis=0)\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        # Agent's name is matched to the array entries for index identification.\n",
        "        # 'current_player.name' should be updated alongside the array values.\n",
        "        current_pos = np.where(self.world == self.current_player.name)\n",
        "        # the current agent must have gas in it.\n",
        "        if self.current_player.gas > 0:\n",
        "            if action == 0:\n",
        "                next_pos = (current_pos[0] - 1, current_pos[1]) # Agent moving upwards.\n",
        "\n",
        "                if next_pos[0] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 1:\n",
        "                next_pos = (current_pos[0], current_pos[1] + 1)\n",
        "                limit = np.size(self.world, 1)\n",
        "\n",
        "                if next_pos[1] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 2:\n",
        "                next_pos = (current_pos[0] + 1, current_pos[1])\n",
        "                limit = np.size(self.world, 0)\n",
        "\n",
        "                if next_pos[0] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            elif action == 3:\n",
        "                next_pos = (current_pos[0], current_pos[1] - 1)\n",
        "\n",
        "                if next_pos[1] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] >= 0 and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            # Newly added logic based on three new possible actions.\n",
        "            elif action == 4:\n",
        "                pass # Corresponding agent selects to not move at their chance.\n",
        "            elif action == 5: # If agent is over the package, it has to pick it up.\n",
        "                # Agent can choose to drop the package, if it is loaded with it.\n",
        "                # After, dropping the package the agent should dissappear.\n",
        "                if self.current_player.package == 3:\n",
        "                    if self.world[current_pos] == 0:\n",
        "                        self.world[current_pos] = 3\n",
        "                        # agent dissappears from the grid after this drop.\n",
        "                    elif self.world[current_pos] == 4: # Added as extra case, functionally shouldn't be triggered.\n",
        "                        self.world[current_pos] = self.current_player.name\n",
        "                        self.state = 'W'\n",
        "        else:\n",
        "            # Player 1's gas is supposed to go empty first.\n",
        "            # Therefore, upon having empty gas tank player should be allowed to\n",
        "            # drop the package in the environment and disappear from the location.\n",
        "            if self.current_player.package == 3:\n",
        "                self.world[current_pos] = self.current_player.package\n",
        "                # agent dissappears from the grid after this drop.\n",
        "            else:\n",
        "                self.world[current_pos] = 0 # If gas is finished, agent should dissappear.\n",
        "\n",
        "        # If gas is empty for both agents, the episode should stop at that instant.\n",
        "        if self.agent_one.gas == 0 and self.agent_two.gas == 0:\n",
        "            self.state = 'L'\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self._take_action(action)\n",
        "        self.current_step += 1\n",
        "        # Uncomment the below statement out, while debugging.\n",
        "        # print(self.world) \n",
        "\n",
        "        if self.state == \"W\":\n",
        "            reward = 1\n",
        "            done = True\n",
        "        elif self.state == 'L':\n",
        "            reward = -10\n",
        "            done = True\n",
        "        elif self.state == 'P':\n",
        "            reward = 0 # sparse reward encoding, only rewarded when episode ends.\n",
        "            done = False\n",
        "\n",
        "        if self.current_step >= self.max_step:\n",
        "            print(f'New episode number {self.current_episode + 1}')\n",
        "            done = True\n",
        "\n",
        "        # agents object used to identify agent properties.\n",
        "        if self.current_player.name == 1:\n",
        "            self.current_player = self.agent_two\n",
        "        elif self.current_player.name == 2:\n",
        "            self.current_player = self.agent_one\n",
        "\n",
        "        if done:\n",
        "            self.render_episode(self.state)\n",
        "            self.current_episode += 1\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, done, {'state': self.state}\n",
        "\n",
        "    def render_episode(self, win_or_lose):\n",
        "        # Storing the rendered episodes in a file.\n",
        "        self.success_episode.append(\n",
        "            'Success' if win_or_lose == 'W' else 'Failure')\n",
        "        file = open('render.txt', 'a')\n",
        "        file.write('----------------------------\\n')\n",
        "        file.write(f'Episode number {self.current_episode}\\n')\n",
        "        file.write(\n",
        "            f'{self.success_episode[-1]} in {self.current_step} steps\\n')\n",
        "        file.close()"
      ],
      "metadata": {
        "id": "8Okx4ARl5Kse"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: The 3x3 road network environment doesn't rotate in its simple\n",
        "# setting implementation.\n",
        "# Implementation of the Simple 3x3 road network for MultiAgent RL.\n",
        "class SizeThreeSimpleGridRoadEnv(gym.Env):\n",
        "    # Defining the Driving Agent with name and gas values plus package flag.\n",
        "    class DriverAgent():\n",
        "        def __init__(self, name, gas, package):\n",
        "            self.name = name\n",
        "            self.gas = gas\n",
        "            self.package = package\n",
        "\n",
        "    def __init__(self):\n",
        "        # super(SizeThreeSimpleGridRoadEnv, self).__init__()\n",
        "        # Defining different possible world configurations.\n",
        "        self.world_one = np.array([[1, 0, 0],\n",
        "                      [3, 0, 2],\n",
        "                      [0, 0, 4]])\n",
        "        # self.world_two = np.rot90(self.world_one)\n",
        "        # self.world_three = np.rot90(self.world_two)\n",
        "        # self.world_four = np.rot90(self.world_three)\n",
        "        # Even the initial world configuration is defined to be different upon\n",
        "        # environment instantiation. \n",
        "        # prob = random.uniform(0, 1)\n",
        "        # Default value assignment below.\n",
        "        self.world = self.world_one\n",
        "        # if prob > 0.25 and prob <= 0.25:\n",
        "        #     self.world = self.world_two\n",
        "        # elif prob > 0.5 and prob <= 0.75:\n",
        "        #     self.world = self.world_three\n",
        "        # elif prob > 0.75 and prob <= 1:\n",
        "        #     self.world = self.world_four\n",
        "        self.world_start = self.world # This 'world_start', if reset() is called, never gets used.\n",
        "        # Adding five actions for the environment.\n",
        "        # 0: up, 1: right, 2: down, 3: left, 4: stay/pass chance, 5: drop\n",
        "        # When agent reaches at package location it automatically picks up the package.\n",
        "        self.action_space = spaces.Discrete(6)\n",
        "        shape_0 = np.size(self.world_start, 0)\n",
        "        shape_1 = np.size(self.world_start, 1)\n",
        "        self.observation_space = spaces.Box(low=0,\n",
        "                                            high=4,\n",
        "                                            shape=(shape_0 + 1, shape_1),\n",
        "                                            dtype=np.int16)\n",
        "        self.reward_range = (-10, 1)\n",
        "        self.current_episode = 0\n",
        "        self.success_episode = []\n",
        "        # Defining the driver agents in the environment.\n",
        "        self.agent_one = self.DriverAgent(1,4,0) # 3 integer value, when carrying package.\n",
        "        self.agent_two = self.DriverAgent(2,4,0) # 3 integer value, when carrying package.\n",
        "\n",
        "    def reset(self):\n",
        "        # Game like formulation, each player agent moves one step at a time.\n",
        "        self.agent_one = self.DriverAgent(1,4,0) # Instantiating agent 1 again.\n",
        "        self.agent_two = self.DriverAgent(2,4,0) # Instantiating agent 2 again.\n",
        "        self.current_player = self.agent_one\n",
        "        # 'P' means the game is playable, 'W' means delivered, 'L' means no delivery.\n",
        "        self.state = 'P'\n",
        "        self.current_step = 0\n",
        "        self.max_step = 30 # agent can choose not move as an alternate choice.\n",
        "        # Selecting a world at random to function with.\n",
        "        # Even the initial world configuration should be different.\n",
        "        # prob = random.uniform(0, 1)\n",
        "        # if prob > 0.25 and prob <= 0.25:\n",
        "        #     self.world_start = self.world_two\n",
        "        # elif prob > 0.5 and prob <= 0.75:\n",
        "        #     self.world_start = self.world_three\n",
        "        # elif prob > 0.75 and prob <= 1:\n",
        "        #     self.world_start = self.world_four\n",
        "        # elif prob < 0.25:\n",
        "        #     self.world_start = self.world_one\n",
        "        self.world_start = self.world_one    \n",
        "        self.world = np.copy(self.world_start) # The self.world can be different from intial world.\n",
        "        # no exploration_prize and bonus_reward as per my design.\n",
        "        return self._next_observation()\n",
        "    \n",
        "    def _next_observation(self):\n",
        "        obs = self.world\n",
        "        data_to_add = [0] * np.size(self.world, 1)\n",
        "        data_to_add[0] = self.current_player.name # adding current player's label in the observation.\n",
        "        obs = np.append(obs, [data_to_add], axis=0)\n",
        "        # Observation Sample provided below for reference:\n",
        "        # last row, represents 'data_to_add' vector.\n",
        "        # array([[1, 0, 0],\n",
        "        #         [3, 0, 2],\n",
        "        #         [0, 0, 4],\n",
        "        #         [1, 0, 0]])\n",
        "        return obs\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        # Agent's name is matched to the array entries for index identification.\n",
        "        # 'current_player.name' should be updated alongside the array values.\n",
        "        current_pos = np.where(self.world == self.current_player.name)\n",
        "        # the current agent must have gas in it.\n",
        "        if self.current_player.gas > 0:\n",
        "            if action == 0:\n",
        "                next_pos = (current_pos[0] - 1, current_pos[1]) # Agent moving upwards.\n",
        "\n",
        "                if next_pos[0] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 1:\n",
        "                next_pos = (current_pos[0], current_pos[1] + 1)\n",
        "                limit = np.size(self.world, 1)\n",
        "\n",
        "                if next_pos[1] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 2:\n",
        "                next_pos = (current_pos[0] + 1, current_pos[1])\n",
        "                limit = np.size(self.world, 0)\n",
        "\n",
        "                if next_pos[0] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            elif action == 3:\n",
        "                next_pos = (current_pos[0], current_pos[1] - 1)\n",
        "\n",
        "                if next_pos[1] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] >= 0 and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            # Newly added logic based on three new possible actions.\n",
        "            elif action == 4:\n",
        "                pass # Corresponding agent selects to not move at their chance.\n",
        "            elif action == 5: # If agent is over the package, it has to pick it up, environment cases encoded above.\n",
        "                # Agent can choose to drop the package, if it is loaded with it.\n",
        "                # After, dropping the package the agent should dissappear.\n",
        "                if self.current_player.package == 3:\n",
        "                    if self.world[current_pos] == 0:\n",
        "                        self.world[current_pos] = 3\n",
        "                        # agent dissappears from the grid after this drop.\n",
        "                    elif self.world[current_pos] == 4: # Added as extra case, functionally possibly won't be triggered.\n",
        "                        self.world[current_pos] = self.current_player.name\n",
        "                        self.state = 'W'\n",
        "        else:\n",
        "            # Player 1's gas is supposed to go empty first.\n",
        "            # Therefore, upon having empty gas tank player should be allowed to\n",
        "            # drop the package in the environment and disappear from the location.\n",
        "            if self.current_player.package == 3:\n",
        "                self.world[current_pos] = self.current_player.package\n",
        "                # agent dissappears from the grid after this drop.\n",
        "            else:\n",
        "                self.world[current_pos] = 0 # If gas is finished, agent should dissappear.\n",
        "\n",
        "        # If gas is empty for both agents, the episode should stop at that instant.\n",
        "        if self.agent_one.gas == 0 and self.agent_two.gas == 0:\n",
        "            self.state = 'L'\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self._take_action(action)\n",
        "        self.current_step += 1\n",
        "        # Uncomment the below statement out, while debugging.\n",
        "        # print(self.world) \n",
        "\n",
        "        if self.state == \"W\":\n",
        "            reward = 1\n",
        "            done = True\n",
        "        elif self.state == 'L':\n",
        "            reward = -10\n",
        "            done = True\n",
        "        elif self.state == 'P':\n",
        "            reward = 0 # sparse reward encoding, only rewarded when episode ends.\n",
        "            done = False\n",
        "\n",
        "        if self.current_step >= self.max_step:\n",
        "            print(f'New episode number {self.current_episode + 1}')\n",
        "            done = True\n",
        "\n",
        "        # agents object used to identify agent properties.\n",
        "        if self.current_player.name == 1:\n",
        "            self.current_player = self.agent_two\n",
        "        elif self.current_player.name == 2:\n",
        "            self.current_player = self.agent_one\n",
        "\n",
        "        if done:\n",
        "            self.render_episode(self.state)\n",
        "            self.current_episode += 1\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, done, {'state': self.state}\n",
        "\n",
        "    def render_episode(self, win_or_lose):\n",
        "        # Storing the rendered episodes in a file.\n",
        "        self.success_episode.append(\n",
        "            'Success' if win_or_lose == 'W' else 'Failure')\n",
        "        file = open('render.txt', 'a')\n",
        "        file.write('----------------------------\\n')\n",
        "        file.write(f'Episode number {self.current_episode}\\n')\n",
        "        file.write(\n",
        "            f'{self.success_episode[-1]} in {self.current_step} steps\\n')\n",
        "        file.close()"
      ],
      "metadata": {
        "id": "2pPscl6L7Wr8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stable_baseline3 library related import statements.\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3 import PPO\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bpbJzTgt5LcI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the environment for testing.\n",
        "env_simple = DummyVecEnv([lambda: SizeThreeSimpleGridRoadEnv()])\n",
        "env_dynamic = DummyVecEnv([lambda: SizeThreeSimpleGridRoadEnv()])"
      ],
      "metadata": {
        "id": "RKQI7GQF5LeI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The environment and model memory cleanup.\n",
        "# del env_simple\n",
        "# del model_simple\n",
        "# del env_dynamic\n",
        "# del model_dynamic"
      ],
      "metadata": {
        "id": "ZiyErS5apSf4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training sample environment policy for checking the env functionality.\n",
        "model_simple = PPO(\"MlpPolicy\", env_simple, verbose=0)\n",
        "model_simple.learn(20000)"
      ],
      "metadata": {
        "id": "4G1wWqMz5Lgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dynamic environment policy for checking the env functionality.\n",
        "model_dynamic = PPO(\"MlpPolicy\", env_dynamic, verbose=0)\n",
        "model_dynamic.learn(20000)"
      ],
      "metadata": {
        "id": "ZvqykykLszbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing sample environment policy for checking the env functionality.\n",
        "result_test = []\n",
        "obs = env_simple.reset()\n",
        "for i in range(300):\n",
        "    action, _states = model_simple.predict(obs)\n",
        "    obs, reward, done, info = env_simple.step(action)\n",
        "    if done:\n",
        "        result_test.append(info[0]['state'])"
      ],
      "metadata": {
        "id": "5WC4ltsc5Li7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b3152e-271b-4ddc-933f-5d3050b1b28d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New episode number 761\n",
            "New episode number 763\n",
            "New episode number 767\n",
            "New episode number 769\n",
            "New episode number 770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the output results w/ successful completions.\n",
        "result_stat = result_test.count('W') / len(result_test)\n",
        "print(f'Success rate: {result_stat * 100} %')\n",
        "# Note: At 50K episodes the PPO surely converges to the optimum cooperative behavior."
      ],
      "metadata": {
        "id": "WgDvXDOkqZwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f55b1c5-e963-490d-9d90-c475398b14c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 61.53846153846154 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing sample environment policy for checking the env functionality.\n",
        "result_test = []\n",
        "obs = env_dynamic.reset()\n",
        "for i in range(300):\n",
        "    action, _states = model_dynamic.predict(obs)\n",
        "    obs, reward, done, info = env_dynamic.step(action)\n",
        "    if done:\n",
        "        result_test.append(info[0]['state'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skOeowRZs_8b",
        "outputId": "3db60dc8-b1fe-48c5-eb65-f3421402e3cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New episode number 723\n",
            "New episode number 724\n",
            "New episode number 725\n",
            "New episode number 726\n",
            "New episode number 727\n",
            "New episode number 729\n",
            "New episode number 730\n",
            "New episode number 731\n",
            "New episode number 732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the output results w/ successful completions.\n",
        "result_stat = result_test.count('W') / len(result_test)\n",
        "print(f'Success rate: {result_stat * 100} %')\n",
        "# Note: At 50K episodes the PPO surely converges to the optimum cooperative behavior."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovv17LmxtAKx",
        "outputId": "63959a50-0572-4542-aaf7-b782289c0b43"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 10.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oS2yYuPPtQq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
