{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stablebaselines_GridRoadEnv_prototyping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing the latest stable-baselines3 library.\n",
        "# !pip install stable-baselines3\n",
        "!pip install stable-baselines3\n",
        "# Ignoring the restart runtime instruction and continue with the cell execution."
      ],
      "metadata": {
        "id": "34ag2hg60oia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W5RN83LAqWyB"
      },
      "outputs": [],
      "source": [
        "# OpenAI gym related import statements.\n",
        "# Building a simpler environment that works with stablebaselines.\n",
        "import os\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np  \n",
        "import random\n",
        "from gym.envs.registration import EnvSpec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: The 3x3 road network environment doesn't rotate in its simple\n",
        "# setting implementation.\n",
        "# Implementation of the Simple 3x3 road network for MultiAgent RL.\n",
        "class SimpleGridRoadEnv(gym.Env):\n",
        "    # Defining the Driving Agent with name and gas values plus package flag.\n",
        "    class DriverAgent():\n",
        "        def __init__(self, name, gas, package):\n",
        "            self.name = name\n",
        "            self.gas = gas\n",
        "            self.package = package\n",
        "\n",
        "    def __init__(self, size, gas):\n",
        "        # size: grid size, gas: values restricted between (n_min: trunc(n/2), n_max: 2*(n-1)-1)\n",
        "        # converting even size to nearest odd number.\n",
        "        self.size = size\n",
        "        if size % 2 == 0:\n",
        "            self.size = self.size+1\n",
        "        # Defining different possible world configurations.\n",
        "        self.world_one = np.zeros((self.size,self.size), dtype=int)\n",
        "        # Setting up env values for the numpy array.\n",
        "        self.world_one[0][0]=1\n",
        "        self.world_one[self.size-1][self.size-1]=4\n",
        "        self.world_one[self.size//2][self.size-1]=2\n",
        "        self.world_one[self.size//2][0]=3\n",
        "        self.world = self.world_one\n",
        "        # if prob > 0.25 and prob <= 0.25:\n",
        "        #     self.world = self.world_two\n",
        "        # elif prob > 0.5 and prob <= 0.75:\n",
        "        #     self.world = self.world_three\n",
        "        # elif prob > 0.75 and prob <= 1:\n",
        "        #     self.world = self.world_four\n",
        "        self.world_start = self.world # This 'world_start', if reset() is called, never gets used.\n",
        "        # Adding five actions for the environment.\n",
        "        # 0: up, 1: right, 2: down, 3: left, 4: stay/pass chance, 5: drop & dissappear\n",
        "        # When agent reaches at package location it automatically picks up the package.\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "        shape_0 = np.size(self.world_start, 0)\n",
        "        shape_1 = np.size(self.world_start, 1)\n",
        "        self.observation_space = spaces.Box(low=0,\n",
        "                                            high=4,\n",
        "                                            shape=(shape_0 + 1, shape_1),\n",
        "                                            dtype=np.int16)\n",
        "        self.reward_range = (-10, 10)\n",
        "        self.current_episode = 0\n",
        "        self.success_episode = []\n",
        "        # Defining the driver agents in the environment.\n",
        "        self.gas = gas\n",
        "        # truncating the gas to the desirable range for experimentation.\n",
        "        if (self.gas < self.size//2) or (self.gas > (2*(self.size-1)-1)):\n",
        "            self.gas = random.randint(self.size//2, 2*(self.size-1))\n",
        "        self.agent_one = self.DriverAgent(1,self.gas,0) # 3 integer value, when carrying package.\n",
        "        self.agent_two = self.DriverAgent(2,self.gas,0) # 3 integer value, when carrying package.\n",
        "        self.spec = EnvSpec(\"SimpleGridRoadEnv-v0\")\n",
        "\n",
        "    def reset(self):\n",
        "        # Game like formulation, each player agent moves one step at a time.\n",
        "        self.agent_one = self.DriverAgent(1,self.gas,0) # Instantiating agent 1 again.\n",
        "        self.agent_two = self.DriverAgent(2,self.gas,0) # Instantiating agent 2 again.\n",
        "        self.current_player = self.agent_one\n",
        "        # 'P' means the game is playable, 'W' means delivered, 'L' means no delivery.\n",
        "        self.state = 'P'\n",
        "        self.current_step = 0\n",
        "        self.max_step = self.gas*3 # agent can choose not move as an alternate choice.\n",
        "        # Selecting a world at random to function with.\n",
        "        # Even the initial world configuration should be different.\n",
        "        # prob = random.uniform(0, 1)\n",
        "        # if prob > 0.25 and prob <= 0.25:\n",
        "        #     self.world_start = self.world_two\n",
        "        # elif prob > 0.5 and prob <= 0.75:\n",
        "        #     self.world_start = self.world_three\n",
        "        # elif prob > 0.75 and prob <= 1:\n",
        "        #     self.world_start = self.world_four\n",
        "        # elif prob < 0.25:\n",
        "        #     self.world_start = self.world_one\n",
        "        self.world_start = self.world_one    \n",
        "        self.world = np.copy(self.world_start) # The self.world can be different from intial world.\n",
        "        # no exploration_prize and bonus_reward as per my design.\n",
        "        return self._next_observation()\n",
        "    \n",
        "    def _next_observation(self):\n",
        "        obs = self.world\n",
        "        data_to_add = [0] * np.size(self.world, 1)\n",
        "        data_to_add[0] = self.current_player.name # adding current player's label in the observation.\n",
        "        obs = np.append(obs, [data_to_add], axis=0)\n",
        "        # Observation Sample provided below for reference:\n",
        "        # last row, represents 'data_to_add' vector.\n",
        "        # A 3x3 observation grid example for reference.\n",
        "        # array([[1, 0, 0],\n",
        "        #         [3, 0, 2],\n",
        "        #         [0, 0, 4],\n",
        "        #         [1, 0, 0]])\n",
        "        return obs\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        # Agent's name is matched to the array entries for index identification.\n",
        "        # 'current_player.name' should be updated alongside the array values.\n",
        "        current_pos = np.where(self.world == self.current_player.name)\n",
        "        # the current agent must have gas in it.\n",
        "        if self.current_player.gas > 0:\n",
        "            if action == 0:\n",
        "                next_pos = (current_pos[0] - 1, current_pos[1]) # Agent moving upwards.\n",
        "\n",
        "                if next_pos[0] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 1:\n",
        "                next_pos = (current_pos[0], current_pos[1] + 1)\n",
        "                limit = np.size(self.world, 1)\n",
        "\n",
        "                if next_pos[1] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            elif action == 2:\n",
        "                next_pos = (current_pos[0] + 1, current_pos[1])\n",
        "                limit = np.size(self.world, 0)\n",
        "\n",
        "                if next_pos[0] < limit and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[0] < limit and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[0] < limit and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            elif action == 3:\n",
        "                next_pos = (current_pos[0], current_pos[1] - 1)\n",
        "\n",
        "                if next_pos[1] >= 0 and int(self.world[next_pos]) == 0:\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos]) in (1, 2):\n",
        "                    pass # Two Agents can't be at the same place.\n",
        "\n",
        "                elif next_pos[1] >= 0 and (int(self.world[next_pos]) == 3):\n",
        "                    self.world[next_pos] = self.current_player.name\n",
        "                    self.current_player.package = 3 # package is also hidden now from other agent.\n",
        "                    self.world[current_pos] = 0\n",
        "                    # Reducing the agent's gas by 1.\n",
        "                    self.current_player.gas = self.current_player.gas - 1\n",
        "\n",
        "                elif next_pos[1] >= 0 and int(self.world[next_pos] == 4):\n",
        "                    # player should only be allowed this transition to this position\n",
        "                    # when it is having the package with it.\n",
        "                    if self.current_player.package == 3:\n",
        "                        self.world[next_pos] = self.current_player.name # like 34 are already there, for example.\n",
        "                        self.world[current_pos] = 0\n",
        "                        self.state = 'W' # and the episode, should end at that moment.\n",
        "                        # Reducing the agent's gas by 1.\n",
        "                        self.current_player.gas = self.current_player.gas - 1\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            # Newly added logic based on three new possible actions.\n",
        "            elif action == 4 and self.current_player.name != 1: # passing is only allowed for agent 2.\n",
        "                pass # Corresponding agent selects to not move at their chance.\n",
        "            '''\n",
        "            elif action == 5: # If agent is over the package, it has to pick it up, environment cases encoded above.\n",
        "                # Agent can choose to drop the package, if it is loaded with it.\n",
        "                # After, dropping the package the agent should dissappear.\n",
        "                if self.current_player.package == 3:\n",
        "                    if self.world[current_pos] == 0:\n",
        "                        self.world[current_pos] = 3\n",
        "                        # agent dissappears from the grid after this drop.\n",
        "                    elif self.world[current_pos] == 4: # Added as extra case, functionally possibly won't be triggered.\n",
        "                        self.world[current_pos] = self.current_player.name\n",
        "                        self.state = 'W'\n",
        "            '''\n",
        "        else:\n",
        "            # Player 1's gas is supposed to go empty first.\n",
        "            # Therefore, upon having empty gas tank player should be allowed to\n",
        "            # drop the package in the environment and disappear from the location.\n",
        "            if self.current_player.package == 3:\n",
        "                self.world[current_pos] = self.current_player.package\n",
        "                # agent dissappears from the grid after this drop.\n",
        "            else:\n",
        "                self.world[current_pos] = 0 # If gas is finished, agent should dissappear.\n",
        "        # If gas is empty for both agents, the episode should stop at that instant.\n",
        "        if self.agent_one.gas == 0 and self.agent_two.gas == 0:\n",
        "            self.state = 'L'\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self._take_action(action)\n",
        "        self.current_step += 1\n",
        "        # Uncomment the below statement out, while debugging.\n",
        "        # print(self.world) \n",
        "\n",
        "        if self.state == \"W\":\n",
        "            reward = 1\n",
        "            done = True\n",
        "        elif self.state == 'L':\n",
        "            reward = -10\n",
        "            done = True\n",
        "        elif self.state == 'P':\n",
        "            reward = 0 # sparse reward encoding, only rewarded when episode ends.\n",
        "            done = False\n",
        "\n",
        "        if self.current_step >= self.max_step:\n",
        "            print(f'New episode number {self.current_episode + 1}')\n",
        "            done = True\n",
        "\n",
        "        # agents object used to identify agent properties.\n",
        "        if self.current_player.name == 1 and self.current_step > self.size//2:\n",
        "            self.current_player = self.agent_two\n",
        "        elif self.current_player.name == 2:\n",
        "            self.current_player = self.agent_one\n",
        "\n",
        "        if done:\n",
        "            self.render_episode(self.state)\n",
        "            self.current_episode += 1\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, done, {'state': self.state}\n",
        "\n",
        "    def render_episode(self, win_or_lose):\n",
        "        # Storing the rendered episodes in a file.\n",
        "        self.success_episode.append(\n",
        "            'Success' if win_or_lose == 'W' else 'Failure')\n",
        "        file = open('render.txt', 'a')\n",
        "        file.write('----------------------------\\n')\n",
        "        file.write(f'Episode number {self.current_episode}\\n')\n",
        "        file.write(\n",
        "            f'{self.success_episode[-1]} in {self.current_step} steps\\n')\n",
        "        file.close()"
      ],
      "metadata": {
        "id": "2pPscl6L7Wr8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stable_baseline3 library related import statements.\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv # it's usage produces 'spec' related error.\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv # it's usage produces 'spec' related error.\n",
        "from stable_baselines3 import A2C"
      ],
      "metadata": {
        "id": "bpbJzTgt5LcI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the environment for testing.\n",
        "env_simple = SimpleGridRoadEnv(5,10)\n",
        "# Logs will be saved in log_dir/monitor.csv\n",
        "# env_simple = Monitor(env_simple, log_dir)"
      ],
      "metadata": {
        "id": "LJjDiyrTkN8O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple = A2C(\"MlpPolicy\", env_simple, verbose=0)\n",
        "model_simple.learn(total_timesteps=400, log_interval=4)"
      ],
      "metadata": {
        "id": "dx5z0giWkOC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63478230-024a-4f14-abef-6c46a9fe7d84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New episode number 2\n",
            "New episode number 3\n",
            "New episode number 4\n",
            "New episode number 5\n",
            "New episode number 6\n",
            "New episode number 7\n",
            "New episode number 8\n",
            "New episode number 9\n",
            "New episode number 10\n",
            "New episode number 11\n",
            "New episode number 12\n",
            "New episode number 13\n",
            "New episode number 14\n",
            "New episode number 15\n",
            "New episode number 16\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.a2c.a2c.A2C at 0x7ff122a952d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DQN Model Learning for Simple Road Environment Task\n",
        "# del env_simple\n",
        "# del model_simple"
      ],
      "metadata": {
        "id": "oHAGMzfMytx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the RL model instances.\n",
        "print(model_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nMQFv0e2mwK",
        "outputId": "c2da1cf3-c9d7-4e3b-f14d-1c21eeda059b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<stable_baselines3.a2c.a2c.A2C object at 0x7ff122a952d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import colors\n",
        "\n",
        "def agent_rendering(obs_list):\n",
        "    fps = 2\n",
        "    nSeconds = 15\n",
        "    # matching the dimension dimension of the obs_list with 'nSeconds*fps' values.\n",
        "    snapshots = obs_list # [ np.random.rand(3,3) for _ in range(nSeconds*fps) ]\n",
        "\n",
        "    # First set up the figure, the axis, and the plot element we want to animate\n",
        "    fig = plt.figure( figsize=(3,4) )\n",
        "    colormap = colors.ListedColormap([\"lightsteelblue\", \"chocolate\", \"tomato\", \"navajowhite\", \"yellowgreen\", \"lightpink\"])\n",
        "    bounds = [0,1,2,3,4,5]\n",
        "    norm = colors.BoundaryNorm(bounds, colormap.N)\n",
        "    a = snapshots[0]\n",
        "    im = plt.imshow(a, cmap=colormap, norm=norm)\n",
        "    def animate_func(i):\n",
        "        if i % fps == 0:\n",
        "            print( '.', end ='' )\n",
        "        im.set_array(snapshots[i])\n",
        "        return [im]\n",
        "    anim = animation.FuncAnimation(\n",
        "                               fig, \n",
        "                               animate_func, \n",
        "                               frames = nSeconds * fps,\n",
        "                               interval = 1000 / fps, # in ms\n",
        "                               )\n",
        "    anim.save('test_anim.mp4', fps=fps, extra_args=['-vcodec', 'libx264'])\n",
        "    print('Done!')"
      ],
      "metadata": {
        "id": "zsOIKNWa6O6y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing obs data into simple road env for ppo algorithm.\n",
        "ppo_simple_obs_list = []\n",
        "env_simple = SimpleGridRoadEnv(5,10)\n",
        "result_test = []\n",
        "obs = env_simple.reset()\n",
        "for i in range(200):\n",
        "    action, _states = model_simple.predict(obs)\n",
        "    # print(action)\n",
        "    obs, reward, done, info = env_simple.step(action)\n",
        "    ppo_simple_obs_list.append(obs)\n",
        "    if done:\n",
        "        result_test.append(info['state'])\n",
        "\n",
        "# Printing the output results w/ successful completions.\n",
        "result_stat = result_test.count('W') / len(result_test)\n",
        "print(f'Success rate: {result_stat * 100} %')"
      ],
      "metadata": {
        "id": "GcOzl_0Tw_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing obs data into simple road env for random walk testing for the environment.\n",
        "import random\n",
        "ppo_simple_obs_list = []\n",
        "env_simple = SimpleGridRoadEnv(5,10)\n",
        "result_test = []\n",
        "obs = env_simple.reset()\n",
        "for i in range(200):\n",
        "    action = random.randint(0, 4) # model_simple.predict(obs)\n",
        "    obs, reward, done, info = env_simple.step(action)\n",
        "    # print(info)\n",
        "    ppo_simple_obs_list.append(obs)\n",
        "    if done:\n",
        "        result_test.append(info['state'])\n",
        "\n",
        "# Printing the output results w/ successful completions.\n",
        "result_stat = result_test.count('W') / len(result_test)\n",
        "print(f'Success rate: {result_stat * 100} %')"
      ],
      "metadata": {
        "id": "okwe12Ni_y3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_rendering(ppo_simple_obs_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "igdSxCaE5M7o",
        "outputId": "4ba8dc74-dc13-496e-8695-a7bae59c4bc6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "................Done!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "save_path = \"/content/videos/result.mp4\"\n",
        "# Compressed video path\n",
        "compressed_path = \"test_anim.mp4\"\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=175 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "2A3yGVZ_3B8v",
        "outputId": "0b037969-4bb7-4e2c-b222-ce2e66cd0bb2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=175 controls>\n",
              "      <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAH2JtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTIgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAhoZYiEABb//vfTP8yy6/c5teOo96KeJl9DdSUBm5bE8OHe+2XOtUcZ3fJut/zIiK2ARIbFPbHDq7pvi5Y8u15f8DGTc2v3Os7+qGCHeDZriM9A0h+5MeX18chy7+HSC0GUR0aKH2fO07N/xMuPbLUbTnlyuT7xwpj45DIiO+4jFYPPXfRxuZDemTt0W6VRwxe9x/1aZ7xuKGDNCKyM5kE5oO8voxB/rJKYlOywq0kE3ntaxxdvAPhbtC2oGwKU4XM34nJnmUhRUqwyvuRvfbOlARDGSlHoukO2HClYvSesfBfoyiPhrv0K8je55sLzayRgaNCAhgOJzQnaK94xltKUoRFNsH9Ccu4/L70OMIHR2sWyoACRGWVcDXy4LpygrQ7DN2ttMWBYp6WkWzcSG6i7dYSVdoRhg7RsEd5ItrV+/XN0Y/hqCwC1KSyS7L7+kk4lI1JmppDe37qwQvECnbrZszeJpgsCdB+FfXpLsL9ZQnawU3AM0JSCFPq5YtP6z2rTS2tVgRORtZH9KQOZaG0KNaYUGKVTyCf7+HE9gSauln3NTYi6Td5PelzF1tOjRyKemw77+Cqv/2aD8okIBQJQXgLCjvI5S3L/h93CNC+YS7hZTn1pVxa9/fjvpkntbEsejhRH8Uf8nwzcduhJxgJi1Td7E7/JER6/LUg7iQDMv993iuYyjfFvEnG1GyZEYOSkGLXvJfpGeWCmjvh4hVfKvJz5+LYD91OUBSpOgmWzpij0EUAv9MP12snlh8rk9vApA+qNQ9q1IhVu9IBdfg5u73EYjijV/M0TuiXfQUkRYsbCIBIi/mhOIg0QszRpy8nTXm8PHq7Perov4LS5zA2GMLbv1QX0YuMqL2bqtLT820obBDcVdvHXyZBoXesOkGAwy/qHPbzTV7hGMiegE/wJzHyszkdslKvZwrKvn8QPZjKaN/ZYEJ1lfnqzMg207Xp8nkEl1RBqDPdOeu8BxJes+rPnTdYGfF82GSba8/PuUnfJWkElZmRgyiedrsDPK3vNUebGz0vhkjJefM4ryq3b4ziVL2beQn1ANuCtuIprWBblzjwkXZk/otltjk8sRaMMSG8z0c7rEISoiUpb2njHJ8GDH+bFAR+ZBMgweqmvVl9p8mA+eU0gepnl4P43es98X5OSFvsUzax2/Z3+RA5yn4wjEZA/8jo7KjP9qE59+f3CjAPmjfdaRMR4a4StoLA9mBz9qsJYL9KrQaGvHGDVS5H3Ci/5h48F1MI0YyhUXfW/hhAq5TuW4WVU49rmD7dffvBR1o7+07/BsCPTDh4+O8yJ78Ep7RfWYBcWYzjhNOrV/balb6MjthJ2PiQycTvvNuush+IQ6ctt4OmuXFNTsgq5YhqhY5rSiBPUjI05Wob2K6LyzPW03E/NJdA9VOSeL7KzobgMRA7P5+M0PkcO/IU1tfiNwCwZJtMqwn2CE4Wq7ot9IJ2mpGdJ+eo9VNCldHrj2dSUk7zVVADTmbhr3TURALrCisztVKYYNRRHd8oMSaJU0+HUeoxEpQyJ/u2CdSCIEO1z+69efANVkt5PaJYmJUOemwpFj6aVWaj8tpR5yHFNSZgsmeJR5nOuaCkyR/8qVhb0QPHGByUrOonuyYjXQpYLUd1pkzK4NZV9ZwbaTOacNavs74iWZHgbBcUovSJ1szu5Vt5yOe2GUcVO6HW7xVRpFtpNBRFM0jwFZyYpsqUkZyPGQlrrG4FCNxwV6mOJKxMCkSI1kVh6Kmro+HtXPDlDTAvVGMdZxMn8eVR2/iDgKXxlO10uU81oP/EinmZbCFwPrBufMuILbXv5WHkCrtvvhNGT1sZ8X0FKrBCu3pJX20KibZ+egrIn2Z+xzRm5FQmJBWSh37qb+6oSuihSL+6zXvMulFaW9LxBuOEHLhEJQdJ3mZFmL9mQH0uovJgLNs0pNtmoWInN8G3yQ9fvRKwEWnkUxP64ClXpUE0es8c7kvoKp418n3RGnRaVpekD1cRjHKoUcW+3/H56nfVsmd+h019NVKyRcGoI+LdOc1CLqSAi8fKZJvoucRMeojh4pPPSXqNOnyfHMPywrarBun0FRADajNfvVnbF124koSD2wSm5kMPXfN8gzikMvlMSbQfzfz7D1+WMR/qNEmkF0ruksIRF8nyOVVWTQBa3Y+rIY6+dQE3x/7xfVn3j85zcfUmPVwClbdzns+IaCyXVjeRPEX2ST/UkRZoQk5lfXBV5ExFt2RrafrL8WjBmonowyLM3IEv9ii03W/ScEPm1EzrTPzU/Q102PBRsLZwttXxOo2LXLykMQJbcbAwj7D9fN0D/+iCXhuGMrPPDVakKBZqXDGOkniw+9wRLTxfz/j3B27HeGfN4GipGo7Vyh0I71qDI5rzPi+PoifSJRRG9/juUsl7uu5WsX1QHkShyxN2YrLQ9WSAr/5VolXhwCliE5XvJPK/N8UFiiA4thPb28tda8oTdiGMG1VXVpH8qDo8Od1t5x++mWdlvnp8tRD3bI4maSjTm74iZwRWFUAjROk0ZU4XvnlPnYlWBGaSdgtyKk4cxHWEyOaVnN7C/pCLJW6trLQj4B554VnvicaNTdA3ggvg2Hv+zINUZAkWOPV9c7QZJsYxlixNmvPbiX84eguHqPoCiOh6k5+CcZkt60oeF4XbR6aoWJ8b894LbA0Zo/MxDiWVSBaptiHtWXQxJOK0sjXS8gAlJMoJsujV1132PACJk49gjKCga+P4NxiDb/1vr/m6MY09fHis29bKiYwzQrPfX1ZVkhQZ2GbDgAEMqIqp/owpsMEq8r6ZCKs8LjfwPnnGf0DmcdcZtu8pvz6Kah+B40YUfDSESsM+LZeMpMrTXTZiCfT0iVoJV6ggFIBQecQAAAP1BmiNsQW/+1qVQAbTfH/TI5xQAccpef7iYNg5XOO0+hTbbZsx89/xFoys95MTQzAkfM5Kt2PjNA26MOhXMicwuAE0RVC3Q/wqAnnjaOfiAzde8pHVcuFkqFiSgpVdRDbEmmnZBZ5GZKgEwF+Wbxms16o+v9fDh2t6xIoNNI/CZsVD9Wf5/ucg3XL0SHW0Q5v4i18Zu+eRsDwWl5z1JLXg/aNXZAHcWvIb2/3EfN6N3krfnRy04JrWZvFPtpQLqpFO3CTYwOxzAxHsXqU8EXot+azY8ld6kkK017gc4vHcwLrw/rUbOZBHMUQolF/ZyyrQ+pdC8j+EXwVHECPcLAAAALUGeQXiCfwAEX8kLeMHw93bFvin0dolQXQBGypSAdfnWtxCXoAWDLTBw9Jyb4wAAANMBnmJqQS8ABpHMoB9FbCpdLTSJ5IW1OaqEyh5N6jfrDSey2c4eADte8udAbsgGf7RpAF30vZrl68utj+/L6WTheXOMFAk8lZ+DzaJjuOocnIB29hj6j9ee9UVgULZXfWN1DjNKrD+ce2v078d3V3ouu7Th+tnRYIrlKKcwh//bAB7rQzOMApR2NYY9Wf/QH0Ic3/T1wHRNuyEA00PwAZYCxYhBoOMHWnquxQDoIbgjBzW/IQ8bv3Qs2A96qEZoEEYMXh0SjPu/GFDDQUZ3YK8+2VdsAAABLkGaZUmoQWiZTBTwX//+2qZYAceMQKABo5mbv2GAMA3+TvHFzJryR6ZfymWlGo3/N1jOcIszFXkf9MjsROD8HHy0WC7YGKAd/taQ5BTlqg8D61g3O6Bft3iZJxjLrSXOF4BPQCvnZuD7jVQSvnBuq/FWahwIpPoUKw8QE94+WSj9s3oDMdKOgZmsdDabs4VEF+CgCqOGtzfLaEjYxSm9kM+9i79fsUyJbSlm+Y6mGrxayCQCju2RRKpAPylwHaMl84xf9XSbn54/gcBIFqE6AQET2Tx/+KRtb/Q0iNZnzmDuE17IvEE2xvXeJ+8kGBDyMRphlYwJqLI8iFLd0ZkEiqn4VVeRXcO9PXJWs2FMZfUF+kIGJjbIylFBQwQRT2yJXvXhegM332ALfePzWA7hAAAAuwGehGpBLwAG4cygH0VsKl0tNG9AARKRGfWJ+0dxuAYHmKtcFuv2yFDb9LR+DzaJk24FujgPWcZML1bXdgGNHWfjWqB2LlDaVMP5V5Vc6BQjYjCurQY/XZfY33a2XUmhWLOx//oliyhF0aDr7w6wIxakH/kX9GF9PT1wHRGsJWZCf6P2qRd3ZWX2ot2Jug888U+HH2PM33aitekD3QrOFoHRZxG900OSuQ7NRn3fKnwfUVeCGqAjhDeWDoEAAACGQZqJSeEKUmUwILf//talUASeDiPcgAtjDHV//7Ptyuvskhj+hRpYilb3lHu8YOYx4J+EvC3txVnY89A74Ce1Czyzc3o96YO+oGGT+9mdOYsCZyK4ZDOL9EvAPuwqq7HGh9swXfBlpjWlZAUyiv7aJZ9w5toayoo3LTMcrllOiS7xbQmjZ6EAAAA+QZ6nRTRMFP8ABRMg9v2vm0TkdNN4AAtMnXPEfgDJXlVwoJz++WhxSzgrOW6BwwaIxzJncvkG4MXf7ztH6tUAAAC0AZ7GdEEvAA4rZd9xCf4EMUE3RXxF0NjYeHp8AwQQ9b8RopPJWfg82iZLWBXI3tVJcRwvW64o4KV0iXm23InNiE1+FktjMv/QKFiBuXNyFmQD6RQzZGF1JoVizfaP5HYsnTJBg6+8OsCMWuk/0Ca+90z09cB0QnB63JdVE+sSCaKrMVr90YrqtDLmD18YdachLiKyzB7oVXim/BjcOJu/OeZtDsoX4KPcnutjRIrYka9te5g6AAAAoQGeyGpBLwAAjvOQATlJ5Kz8Hm0TJvwKljezhCHt3Zbjj6h5zjSfl642xRxQ7fiioSe16BQkyqcubjvMgH0ilDcMLqTQrFm+GfrgBTPo6NB194dYEYteD/kX9mGhz09cB0P6JGXK6LBXylFryYXPqNJ1qYxKI2cnnCQPTyiF+mGtHYuZRkw5yfuT+sowOB4KNZFWo+sTa9a1MvEMpj2nKbroAAABGEGazUmoQWiZTAgt//7WpVAEkKTWIvVUAc5EiAm3OcUXk0lNayABdVcB/XzUseoVNg50Nh35PcCJq8SdKXZoODrWesvaX7q22CC5EFexj/pmVLHjNBA2Pxxfwy8MWA4FCWT4UvXSxK/pomXg3gzP4EJAFjZUnVQY2mMSJ43YC8MvZV/vbfbeIa0u9boftTMlQUgpi6O+gM/F96vO6DUa0y4hgNXq7a6w2u0gAS3OcDwkcIHbmql/QI4Mq2qq4t3C9jyp1Vg/WNriUfwwN30OnSUnXDwwuaTIA1yPfsar6vIDX8kfgM7WPK5Je7Sj3Ihq4nCknehUJyVqzYBCy8BiSN1/LFPCH8seCaWcsRqlHdmTSm92pGWwkkcAAAB4QZ7rRREsFP8ABRMg9v23aAC6uP/4Ka75jURzuYdDgU6MXJ0W2H/3sD5HXTMC4l25+UH80JQog5PDdoBhXVsjXl8FgCxxqgFgoH4l+pKzmMdLGzbhhOAX0piazkd89xQv2vMIxih4yX7RiVQYcM5wcuiyqcC0cY8OAAAAtwGfCnRBLwAOK2XfcP8KRDF6YK4pHW/fwGA8piIn9lNU+0QAE5SeSs/B5tEyga5u2LN4z2T7hBgJSpi0UOk7Yt8ha+zRmokn0gP9AoUyLhXVnufrsvsf1EMLqTQrFnYef0SxZSLaNB194dYEYtPw/oE19MNQbi4DoimEXMfMV9V4Rq3ZWX2ozKxQhKVPIWsYxRLf3aj2VmD3QrCF0HSPxSd1PF3R4dMoz7vkxdgpLWQvAOMIWG6VSAAAAM0BnwxqQS8ADYOZQD6LxfR9LbRiMqat9+SrfIvDKm2H1UjDMWy0CwrQJQrzWZfll89zi+BTKBVFPikaf+uOAEzSeSs/B5tEx/i0s7fsZk78VIcriHKQJQ6Twgvp8L8yltb57lnQKFP6le6TTc8ldnonWqfWK9p/xc/7ZYsi9+vdFVBPBgweI1/kX+42yi8m8DolKeF7Hpf4sP49EeEHEgzKx0hKOkzXxEKkzMavnsrMHuhXUTMzgb80ePtI++dQX4LAwWsV4SP/BrDg1O2hAAABg0GbD0moQWyZTBRMFv/+1qVQlissADmGDOY9C2Ngnk7/4SQmxfwl5tgsKO064uykgDu/T4s97+5hN0f/9Hd9PYjiB1uUS2bDQQWufVcOKqOSEihms6RjctbzK0XQO/LLoy6BSJB78lvB5bW0Nf+RCxldZtUb+HRfrIJ5mnkzMBi81rSWQPGnvnLSu9lHRDGI1r5iA5RMtkuHPwCUCkzFlWakMakBvIDp6NP/TIl7ofZ059gHk8tAzCmyB3LqLFstxal/HpNPqxOEMiWwGdJD1HjR+nLGYFFdU0JHHJnjjRPTqh2DWbY4ov+svC1iCV7JnfmqkHHy+Bb/1p6nTQaclNNQGu5KbzhdDPiDTbzs/LofwPAoB07pCmTqaIwTk1A3kiQY6jxS1eEp+trZSrJVULu6MCH6sBrYKJZp2JqWvke671821iS5G+7bgHNVXLtMwxTKBsDnrHBiMKElXXHT+3RaqhKnCpdm6DMawzAApvmVbxZ53daVdGFjigEFYInw3MyNbwAAANYBny5qQS8APVkNkXG0aP+RKmn3+Fq8qM3ABbUqM8WrWMucurrgQiU3bUD2wdonRs7QOfG/TfPGaBYl4qceo4R9ke3gQ8fgPCvtm3fKvepSLbyguSsuqo/jIcRAmNyDWVyHHETK9IuIlWQ/lrX6eTTpi0cwT76eB/ick7u3CGj1N/jOB8p+pbStLZ4+3oLR/QIbg/3Onx1R+7AivRkm9fLmfAkzooxF51S33ylXxsgCg6xuaA7wReN9QTEbaHbAacZ4IuppbIsUEUgQbiWkaf5SeHC1p8O1AAAAE0GbM0nhClJlMCC3//7WpVAABlwAAAB6QZ9RRTRMFP8AASS0r87F+loA3G5R34ZOWWb5XeyMM85w1AhQSkt1LQsd15enX1dYFdHzCHaG/e4Uqx4t2TScc7Py5ueSCs4gf8W3bXEk4LOXD/tSYJo0pc4yXmA9oKvqvuknDNMX8CFQgA4nEFmF1LvB79/kxYxFMzgAAACvAZ9wdEEvAAM23KE+1eQzIw9MFcQ3YNvpdABOUnkrPwebRMm/AqWN7OEIe3dluOPqHZKRpPy9cbYo4odvxRUJBTOgULBqcubjvMgH0ilDcMLqTQrFm+GfrgBTPo6NB194dYEYteD/kX9Kz+i8m8Dof0SMuV0WCvlKLcVZfUvxIYsB5ccYvfxjDHSGGLCsbv3QqyjIDnJ72Pex1wYA+OQL8FHV/DG/J5u1yYg9j3MHQQAAALABn3JqQS8AAzbmUA+ithUulppE8kGaUJ30ugAnKTyVn4PNomTfgVLG9nCEPbuy3HH1DslI0n5euNsUcUO34oqEgpnQKFg1OXNx3mQD6RShuGF1JoVizfDP1wApn0dGg6+8OsCMWvB/yL+lZ/ReTeB0P6JGXK6LBXylFuKsvqX4kMWA8uOMXv4xhjpFKVhWN37oVZRkBzk97HvY64MAe/IF+Cjq/hjfk83a5MQex7mDoAAAAV9Bm3VJqEFomUwU8Fv//talUASeDiOdxiKCu4RMskfw/WACzMJRIiqmOhV7eTAMimFYeYD9VjThPXBpWnqxAyLTg5RhotSdTveGxsRIsi+/NlPAYWIcZlDYsEpXOZ/JBW3c0raLse2MpjwnRzkN7jfXSVuHG+9hsc5PPGKbGMEySi8cen3DQQf5ryJPkG/fqBZp8KO/tXqk3cw/NhvQYb8yOJAeqznwYKOVDJOliDcnh1dt3l0SUECKH8j5N0NpJLY0zeeRKwwtBvZagcW4aS4E40WpAE0e0AhzGW/6mgSyrwf5mfyNTh6GQoEN3c93sTWmUO+zF36/qmmjMMA9O3VPx85Kc4rwCdjU3DPPUzePa77Bg4iS4DFMgekyv0fzwVV/7847Q9vk9kwH3vzvs6eeVRSH4fKmK1pd2Eirtuq2DdNh/nN0g2e/JzWpaVJEOLW8Co0Is5dWYsV3BJnxpPQAAADbAZ+UakEvAA4qX52OH4vrYOmytH/qyAL2ZG4ALapvvdImWyZ3X2897SdeeX800o1hFS11BHWnTEq69COaXjVBahVZzBrGNC5xj7OCWvpm3fKveoOVR8YmcljZu9JJlBzNNlJ0NgpzxlL1CNAs0R3Ahfp5Tqn2vCY/XZfXE77vkU6k++xm/tqA+FmbGxHDuzI4q+Uv8ixzY/kLbi9dneJH3JXHlfUO8z/FBzhDdhy6FUg3ttIxaHmkk/yjReN9PZh6Oif8A6liQEV2C8jhFILA+clXk7PYJlDDlPSBAAAAE0Gbl0nhClJlMFLBb/7WpVAABlwAAAChAZ+2akEvAACO85ABOUnkrPwebRMm/AqWN7OEIe3dluOPqHnONJ+XrjbFHFDt+KKhJ7XoFCTKpy5uO8yAfSKUNwwupNCsWb4Z+uAFM+jo0HX3h1gRi14P+Rf2YaHPT1wHQ/okZcrosFfKUWvJhc+o0nWpjEojZyecJA9PKIX6Ya0di5lGTDnJ+5P6yjA4Hgo1kVaj6xNr1rUy8QymPacpuukAAAD1QZu7SeEOiZTAgp/+1oywCC8jXABx1b/4LJD+ei9gMMESygqdGMHQ0oeDIOwODZZRlNZFeP7wx/0zIssfCbmzrh8USWeeqgA7jw8o+MQMAKJXdpCJMi0TgoHI4APqIis1ESODTTjXBLnRjTfEd39BSEJk6gG5FCYZe/WIPR+h3k9NknsMtGGkiAyJRUsLZ7TkCPySEGGzeXOyv5byoG0Ji1GZ35VmNGu4cNRFV26Fv6HNy/mRdbDkEFxi+AxQKeT2yPRN0BwgXMuut3sb7AuIMJvdxvA7lYuDo4ZiYaHplYmNTnbli3pzW9+dyIBCyvjRq4A0e2EAAABAQZ/ZRRU8FP8ABRNJ3zsX37eh3Y5M+uL6ZCONfyeG2236BoJZl/zEGybxIU0rfevpKIZRk7YE2Rizw3Y7WYQygAAAALoBn/h0QS8ADiqUyYTcYAH6cB279rLc8M5DCHrk3qN+sNKZEOTHrgaACcpPJWfg82iZI7gIsHzqEuO9KsEGqrLVMaTvX1O2pxv/PgsHndtfp5SMDCqPTMCJYVo6AbsfL16kNgP+G4KZyaG3sLWfjVbbuMf5GF/93ovJvA6IoGwFOkeod5Ze3I2ZkrCzy65KUynt566CGZNUrCsbv3QrH6c12FFHyS5mzkYVmjPu9+0/9MIksxJR1aeGmOkAAACyAZ/6akEvAA4qX52OBaapc8NXFcO7rfv4DAeRJ0CAA/LfpaPwebRMlrArkb5qquJUXrdckcFI3Gk/fsInNiE1+FktjNb7X6eMBuXNyFmQD6RQzZGF1JoVizfaP5HYsnTJBg6+8OsCMWuk/0Ca+lRz09cB0QnB63JdVE+sSCam17uBX2Eu5KGXMHr4w605D3lhWN37oVXim/BjcOJu/OeZufsgX4KPcnutjRIrYka9te5g6AAAACxBm/1JqEFomUwU8Ev//rUqgCKBxhtv0kxYOb5v6tBg3Ihq3XfXSpBCr3AGYQAAALYBnhxqQS8ADipfnY4FprDZ6b06DLG9igGA8piIf+KJ3DGAD8t+lo/B5tEyga5u2LO5VWT1xW13OEw9kOk7Yt7dygtX2QSF8dvtfp3cRhXVnufrsvscztbLqTQrFnY7P0SxZQy6NB194dYEYtRp/yL+jIpReTeB0RTCLmQc+vbv9A07a97Yr7CdclKnkLN8Yj5P7tR7KzB7oVhC6Do04jm6eHJ/IdMoz7vkxdgpKu/rpAWgw90qkQAABHNtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAA6mAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAADnXRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAA6mAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAA2AAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAOpgAAEAAAAEAAAAAAxVtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAAEAAAAPAAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAALAbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAACgHN0YmwAAACYc3RzZAAAAAAAAAABAAAAiGF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAA2AEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAyYXZjQwFkAAz/4QAZZ2QADKzZQ4JeXhAAAAMAEAAAAwBA8UKZYAEABmjr48siwAAAABhzdHRzAAAAAAAAAAEAAAAeAAAgAAAAABRzdHNzAAAAAAAAAAEAAAABAAAA+GN0dHMAAAAAAAAAHQAAAAEAAEAAAAAAAQAAgAAAAAACAAAgAAAAAAEAAGAAAAAAAQAAIAAAAAABAACgAAAAAAEAAEAAAAAAAQAAAAAAAAABAAAgAAAAAAEAAKAAAAAAAQAAQAAAAAABAAAAAAAAAAEAACAAAAAAAQAAYAAAAAABAAAgAAAAAAEAAKAAAAAAAQAAQAAAAAABAAAAAAAAAAEAACAAAAAAAQAAYAAAAAABAAAgAAAAAAEAAGAAAAAAAQAAIAAAAAABAACgAAAAAAEAAEAAAAAAAQAAAAAAAAABAAAgAAAAAAEAAGAAAAAAAQAAIAAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAB4AAAABAAAAjHN0c3oAAAAAAAAAAAAAAB4AAAsdAAABAQAAADEAAADXAAABMgAAAL8AAACKAAAAQgAAALgAAAClAAABHAAAAHwAAAC7AAAA0QAAAYcAAADaAAAAFwAAAH4AAACzAAAAtAAAAWMAAADfAAAAFwAAAKUAAAD5AAAARAAAAL4AAAC2AAAAMAAAALoAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the '.mp4' video into a '.gif' file.\n",
        "from moviepy.editor import *\n",
        "clip = (VideoFileClip(\"test_anim.mp4\"))\n",
        "clip.write_gif(\"video.gif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_6_1cMwYJLE",
        "outputId": "9bfa27de-b487-4ba7-928a-52749b6f6eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3235840/45929032 bytes (7.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7176192/45929032 bytes (15.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11091968/45929032 bytes (24.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15106048/45929032 bytes (32.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19021824/45929032 bytes (41.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22798336/45929032 bytes (49.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26697728/45929032 bytes (58.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30572544/45929032 bytes (66.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34316288/45929032 bytes (74.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38027264/45929032 bytes (82.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41918464/45929032 bytes (91.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45801472/45929032 bytes (99.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n",
            "\n",
            "[MoviePy] Building file video.gif with imageio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 40/41 [00:00<00:00, 102.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WJtUoz0_5A-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}